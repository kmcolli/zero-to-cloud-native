{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IBM Cloud Satellite Tutorial Series Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) Introduction IBM Cloud\u00ae Satellite helps you deploy and run applications consistently across all on-premises, edge computing and public cloud environments from any cloud vendor. It standardizes a core set of Kubernetes, data, AI and security services to be centrally managed as a service by IBM Cloud, with full visibility across all environments through a single pane of glass. The result is greater developer productivity and development velocity. To learn more about IBM Cloud Satellite click here: https://www.ibm.com/cloud/satellite OR Follow this tutorial series that will go step by step in creating a satellite location, deploying an OpenShift Cluster to the location, and deploying an application to the cluster in your new location. As a note, this is part of the zero to cloud native tutorial series ( https://www.zero-to-cloud-native.com ). We have created this satellite section as a stand-alone tutorial for provisioning and deploying an IBM Cloud Satellite location. You can combine these tutorails with all the ones you will find in zero to cloud native or just go through the satellite tutorials. Tutorials Start here! This tutorial will guide you through a step by step process in creating a satellite location, provisioning infrastructure, creating an IBM Cloud Managed OpenShfit Cluster in your new satellite location. Create a Satellite Location and OpenShift Cluster Create Private Only Infrastructure IBM Cloud VPC Create Private VPN Connectivity to your location . Install Cloud Pak for Data on IBM Cloud Satellite . This section also covers how to setup up Portworx and Cloud Object Storage as the image registry for Satellite. Expose and application running on IBM Cloud Satellite with a Load Balancer .","title":"Home"},{"location":"#ibm-cloud-satellite-tutorial-series","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) Introduction IBM Cloud\u00ae Satellite helps you deploy and run applications consistently across all on-premises, edge computing and public cloud environments from any cloud vendor. It standardizes a core set of Kubernetes, data, AI and security services to be centrally managed as a service by IBM Cloud, with full visibility across all environments through a single pane of glass. The result is greater developer productivity and development velocity. To learn more about IBM Cloud Satellite click here: https://www.ibm.com/cloud/satellite OR Follow this tutorial series that will go step by step in creating a satellite location, deploying an OpenShift Cluster to the location, and deploying an application to the cluster in your new location. As a note, this is part of the zero to cloud native tutorial series ( https://www.zero-to-cloud-native.com ). We have created this satellite section as a stand-alone tutorial for provisioning and deploying an IBM Cloud Satellite location. You can combine these tutorails with all the ones you will find in zero to cloud native or just go through the satellite tutorials.","title":"IBM Cloud Satellite Tutorial Series"},{"location":"#tutorials","text":"Start here! This tutorial will guide you through a step by step process in creating a satellite location, provisioning infrastructure, creating an IBM Cloud Managed OpenShfit Cluster in your new satellite location.","title":"Tutorials"},{"location":"#create-a-satellite-location-and-openshift-cluster","text":"","title":"Create a Satellite Location and OpenShift Cluster"},{"location":"#create-private-only-infrastructure-ibm-cloud-vpc","text":"","title":"Create Private Only Infrastructure IBM Cloud VPC   "},{"location":"#create-private-vpn-connectivity-to-your-location","text":"","title":"Create Private VPN Connectivity to your location. "},{"location":"#install-cloud-pak-for-data-on-ibm-cloud-satellite","text":"","title":"Install Cloud Pak for Data on IBM Cloud Satellite.  "},{"location":"#this-section-also-covers-how-to-setup-up-portworx-and-cloud-object-storage-as-the-image-registry-for-satellite","text":"","title":"This section also covers how to setup up Portworx and Cloud Object Storage as the image registry for Satellite."},{"location":"#expose-and-application-running-on-ibm-cloud-satellite-with-a-load-balancer","text":"","title":"Expose and application running on IBM Cloud Satellite with a Load Balancer.  "},{"location":"cp4d/satellite-cp4d/","text":"Install Cloud Pak for Data on IBM Cloud Satellite Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) 1 - Introduction In this section, we will be provisioning Cloud Pak for Data on our satellite location. One of the most important parts of Cloud Pak for Data is the storage that you will use in your cluster. To get the best performance for Cloud Pak for Data we will be creating Block storage in our VPC and then use Portworx Software Defined Storage, provisioned from the IBM Cloud Catalog, to handle the storage needs for Cloud Pak for Data. By default, when you create an IBM Cloud Managed OpenShift cluster on a Satellite location, the internal image registry is create using emptyDir. This means that images in your cluster will be stored locally on the image registry pod itself. If the pod goes down, you will lose your images. The reason this is initially created like this is to give you flexibility to use the backing of your choice for your image registry. With your satellite location being on prem, at the edge, or maybe a third-party cloud provider there are many options you can choose from meeting your business requirements. A great choice to use for an image registry is IBM Cloud Object Storage which we will setup to use as our image registry backing. 2 - Image Registry When you install Cloud Pak for Data, the installer is going to copy the images Cloud Pak for Data will use to your local image registry. This is done to greatly improve the speed of the installation process. The first thing we are going to do is create an IBM Cloud Object Storage instance and bucket. Note: if you already have an instance of IBM Cloud Object Storage you can skip to section 2.2 2.1 Provision IBM Cloud Object Storage To provision IBM Cloud Object Storage, from the cloud.ibm.com portal, click on Catalog, search for Object Storage and then click on the Object Storage tile. On the next screen, you will want to give the instance of IBM Cloud Object Storage a meaningful name, I will use Cloud Object Storage-Satellite and choose the resource group where your satellite resources are to location to keep things organized. 2.2 Create a Bucket for your Image Repository The next thing we need to do, is create a bucket for our image registry. This bucket needs to have a couple specific settings so please make sure to closely follow the guide here. From your cloud object storage instance, click on Buckets and then Create bucket. Next, click on Customize your bucket: On the next screen, name your bucket something meaningful, I will use sat-cluster-image-registry-kmc. Note: the name of your bucket must be unique in the region where you are creating it, so you may want to use your initials like I have. Select Regional for resiliency, Location: us-east and then standard as the storage class. Note: With the exception of location, this should be whatever region is closest to your satellite location, it is important to select the values exactly as indicated. After entering these settings, click on Create Bucket . Now that we have created a bucket, the next step is to create Service Credentials so that our OpenShift cluster can talk to our instance of Cloud Object Storage to read and write images to the bucket we created. On the left-hand navigation pane, select Service Credentials and then click on New Credential . On the next screen, give your credentials a meaningful name, I will choose Service-credentials-satellite-registry , role should be Write and turn on HMAC . On the next screen, note down the apikey for the Cloud Object Storage Instance, the Access Key and the Secret Access Key. Make sure not to share this with anyone ... by the time anyone reads these I will have deleted these keys. 2.3 Configure OpenShift to use Object Storage for the Image Registry Next, we need to create a secret for our image registry to talk to Cloud Object Storage. Start your terminal, log into IBM Cloud and your cluster. ibmcloud login --apikey= ... not the Object Storage API Key ibmcloud ks cluster config --cluster --admin Change the following command to use oc create secret generic image-registry-private-configuration-user --from-literal=REGISTRY_STORAGE_S3_ACCESSKEY= --from-literal=REGISTRY_STORAGE_S3_SECRETKEY= --namespace openshift-image-registry Now that we have our secret configured, we need to update the configuration of our image registry to point to the object storage instance and bucket we created. The easiest way to do this, is through the OpenShift web console. From cloud.ibm.com navigate to your satellite cluster and then click on OpenShift web console. Once the OpenShift console opens, click on Search , search for ' Config ' and the click on the Config -- imageregistry.operator.openshift.io ... On the next screen, click on cluster. Click on YAML and then scroll down until you see this section: managementState: Removed proxy: http: '' https: '' noProxy: '' httpSecret: dAagViLyMeJodISdQpqcXtodpd6c6ojGyZeGEFnKTjhvpsalEs6vF33Hz5iSldS6 storage: {} We need to make changes to the managementState and the storage lines. *Note -- when you make these changes, you may find you get a warning that object changed and you will need to reload it before you can make changes. You may need to try these a couple of times. One tip I found is change the managementState first and then go back and change storage. What you will need to do, is change managementState to Managed: managementState: Managed and under storage enter the following with your bucket name: storage: s3: bucket: sat-cluster-image-registry-kmc region: us-east-standard regionEndpoint: 'https://s3.us-east.cloud-object-storage.appdomain.cloud' virtualHostedStyle: false After entering these settings, click Save and then Reload. You should see the YAML has been updated with the settings you entered. If you switch to the details page and scroll down, you should see a message that the S3 bucket exists: If you don't see this verify you entered your object storage secrets correctly and try to edit the config yaml again. If it fails again, delete the config and start over. When you delete the config, a new one will top up a couple of seconds later. One additional check we can do to make sure the image registry really is configured, is looking at the image registry pod. To find out if the registry is running as it should, click on Workload and the Pods . Under project , search for and select openshift-image-registry and click on the image-registry pod. On the next screen, click on the Environment tab make sure you see that your object storage is indicated. If you don't see object storage values like below, then try updating the config again. 3 -- Configure Storage 3.1 Provision Block Storage Not surprisingly from the name, Cloud Pak for Data requires storage to store data to perform analytics among other things. With our cluster running on a Virtual Private Cloud, the best choice of storage is Block storage. To create block storage on IBM Cloud, from the VPC, click on Storage , Block storage volumes and then click Create . We will need to create one block storage volume for each worker node. Starting with zone 1 worker 1, enter the following settings: Name: zone1-worker1-volume Location: Dallas1 Scrolling down further, under Volume profile , select Custom and then enter 6000 for IOPS and 500 for the size. Finally, click Create Volume. Repeat the same steps for all the other worker nodes. As a tip: you can also create these block volumes with the CLI using the following command: ibmcloud is volume-create zone2-worker1-vol custom us-south-2 --iops 6000 --capacity 500 3.2 Attach the Block Volumes to your instances Now that we have block volumes created for all our worker nodes we need to attach them. To attach the block volumes, from the VPC Menu, select Virtual Server Instances. For each worker node instance, click on the name. Scroll down to the Storage volumes section and click on Attach. On the next screen, select the block volume for the corresponding Virtual Server Instance and click save. Repeat the same process for the remaining worker nodes. 3.2 Provision Portworx The last step to prepare for Cloud Pak for Data installation is to provision an instance of portworx and since our cluster is a satellite cluster we can do this with the IBM Cloud Catalog. When you install portworx, you have two options to use for the portworx configuration. You can use either the internal kvdb that portworx provides or use an external etcd such as IBM Cloud Databases for etcd. From experience, I highly recommend to use an external etcd to use for you portworx kvdb. The reason for this is if you use the internal kvdb and you reload or replace one your worker nodes, your portworx configuration will fail. While you won't lose any data, you will have to go through a rather painful process of fixing your portworx configuration. It only takes about 5 extra minutes to setup an external etcd system and you get a piece of mind that your portworx configuration will be highly available and rock solid. 3.2.2 Provision IBM Cloud Databases for etcd To install IBM Cloud Databases for etcd, from the cloud.ibm.com console, click on catalog, search for etcd and then click on the Databases for etcd tile. The first thing we need to do is to specify a location for our IBM Cloud databases for etcd to run. For best performance, you will want to select the location that is nearest is your satellite location. Next, we need to enter the following specific settings for etcd to support portworx. Start by giving your etcd instance a meaningful name, I will use Databases for etcd-px-satellite and choose the same resource group your cluster is in. Next, select the following options for etcd and then click Create to create the instance of etcd. Initial memory allocation: 8GB/member (24GB total) Initial disk allocation: 128GB/member (384GB total) Initial CPU allocation: 3 dedicated cores/member (9 cores total) Database version: 3.3 The next think we need to do is generate service credentials for etcd so that portworx can use this etcd instance. After your instance is created it, click on it and the click on service credentials from the menu and finally click on New Credential. {width=\"6.5in\" height=\"3.43125in\"} On the next screen, give your credentials a meaningful name, I will use Service Credentials-px-etcd . Next, we need to retrieve a couple of values from the service credentials we just created. The three values that we need to copy are: certificate_base64 username password We we are going to do is create a Kubernetes secret with these values. The certificate value we can us as-is. The username and password we will need to base64 encode. To do so, start your terminal and enter the following command: echo -n | base64 Repeat the same steps to base64 encode the password. Now that we have the values we need, we can create a Kubernetes secret with these values. Create a new file, I will just name it px-secrets.yaml with the values you just retrieved. apiVersion: v1 kind: Secret metadata: name: px-etcd-certs namespace: kube-system type: Opaque data: ca.pem: \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUREekNDQWZlZ0F3SUJBZ0lKQU5FSDU4eTIva3pITUEwR0NTcUdTSWIzRFFFQkN3VUFNQjR4SERBYUJnTlYKQkFNTUUwbENUU0JEYkc5MVpDQkVZWFJoWW1GelpYTXdIaGNOTVRnd05qSTFNVFF5T1RBd1doY05Namd3TmpJeQpNVFF5T1RBd1dqQWVNUnd3R2dZRFZRUUREQk5KUWswZ1EyeHZkV1FnUkdGMFlXSmhjMlZ6TUlJQklqQU5CZ2txCmhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBOGxwYVFHemNGZEdxZU1sbXFqZmZNUHBJUWhxcGQ4cUoKUHIzYklrclhKYlRjSko5dUlja1NVY0NqdzRaL3JTZzhublQxM1NDY09sKzF0bys3a2RNaVU4cU9XS2ljZVlaNQp5K3laWWZDa0dhaVpWZmF6UUJtNDV6QnRGV3YrQUIvOGhmQ1RkTkY3Vlk0c3BhQTNvQkUyYVM3T0FOTlNSWlNLCnB3eTI0SVVnVWNJTEpXK21jdlc4MFZ4K0dYUmZEOVl0dDZQUkpnQmhZdVVCcGd6dm5nbUNNR0JuK2wyS05pU2YKd2VvdllEQ0Q2Vm5nbDIrNlc5UUZBRnRXWFdnRjNpRFFENW5sL240bXJpcE1TWDZVRy9uNjY1N3U3VERkZ2t2QQoxZUtJMkZMellLcG9LQmU1cmNuck03bkhnTmMvbkNkRXM1SmVjSGIxZEh2MVFmUG02cHpJeHdJREFRQUJvMUF3ClRqQWRCZ05WSFE0RUZnUVVLMytYWm8xd3lLcytERW9ZWGJIcnV3U3BYamd3SHdZRFZSMGpCQmd3Rm9BVUszK1gKWm8xd3lLcytERW9ZWGJIcnV3U3BYamd3REFZRFZSMFRCQVV3QXdFQi96QU5CZ2txaGtpRzl3MEJBUXNGQUFPQwpBUUVBSmY1ZHZselVwcWFpeDI2cUpFdXFGRzBJUDU3UVFJNVRDUko2WHQvc3VwUkhvNjNlRHZLdzh6Ujd0bFdRCmxWNVAwTjJ4d3VTbDlacUFKdDcvay8zWmVCK25Zd1BveU8zS3ZLdkFUdW5SdmxQQm40RldWWGVhUHNHKzdmaFMKcXNlam1reW9uWXc3N0hSekdPekpINFpnOFVONm1mcGJhV1NzeWFFeHZxa25DcDlTb1RRUDNENjdBeldxYjF6WQpkb3FxZ0dJWjJueENrcDUvRlh4Ri9UTWI1NXZ0ZVRRd2ZnQnk2MGpWVmtiRjdlVk9XQ3YwS2FOSFBGNWhycWJOCmkrM1hqSjcvcGVGM3hNdlRNb3kzNURjVDNFMlplU1Zqb3VaczE1Tzkwa0kzazJkYVMyT0hKQUJXMHZTajRuTHoKK1BRenAvQjljUW1PTzhkQ2UwNDlRM29hVUE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCgo=\" username: \"aWJtX2Nsb3VkX2UzNzcxNDZlXzE1MDZfNDdhZF9hZGFjX2JiMjI0YzlhMjViYQ==\" password: \"ZmQzZTljNDcwOTliM2EzOTliNDVmMGYyY2YwMGE5NTEzYjJmZTI0ZGI3NTVjODAwYjNmYw==\" The last step we need to do before we install portworx is creating the secret in our cluster. After logging into your cluster from the command line, run: oc create -f px-secret.yaml 3.2.3 Provision Portworx from the IBM Cloud Catalog From the IBM Cloud console, click on Catalog, search for Portworx and then click on the Portworx Enterprise tile. Start by selecting the region that is connected to your satellite location. I am using us-east Washington DC. For pricing plan, choose the Enterprise plan. For setting, start by giving your portworx instance a meaningful name such as Portworx Enterprise-satellite and choose the same resource group you have been using for all your resources. Enter your cloud API key ( note: you need to enter this API key before you are able to select the cluster to install portworx in). Finally, in this section give a unique name for portworx cluster ( note this is not a kubernetes cluster but rather a portworx storage cluster that runs inside your openshift cluster ). I will use px-cluster. Next, we need to get our endpoint for our etcd service. In a new window, navigate back to your service credentials for etcd instance and copy the endpoint. Enter the following settings: For etcd endpoint enter etcd: Select the satellite cluster you want to install portworx on. For secret name, enter the name of the secret you created. If you followed my yaml example the secret name is px-etcd-certs After entering all of these settings click on Create . 3.2.4 Check Portworx installation It is always a good idea to make sure portworx has been successfully installed on your cluster before you proceed. To do so, log into your cluster through your terminal. After logged in, change to the kube-system project. oc project kube-system Search for portworx pods and note the name of one the pods that starts with portworx... Next enter the following command substituting the name of the portworx pod you just noted. kubectl exec portworx-7czms -it -n kube-system -- /opt/pwx/bin/pxctl status After entering that command, you should see output like the above. Check to make sure the status is online and that you have a storage node for each of your workers. 4 -- Provision Cloud Pak for Data At this point, we have completed all the required pre-reqs to now install Cloud Pak for Data through the IBM Cloud Catalog. To get started, from the IBM Cloud catalog, search for Cloud Pak for Data and then click on the tile. On the next screen, select the satellite cluster you want to install Cloud Pak for Data on, and create a new project for cloud pak for data, I like to use cp4d. Scroll down to the preinstallation section and click on Run Script. In a couple of minutes, you will see a green box showing the preinstallation script was successfully ran. Next, we need to specify which storage class to use. As you can probably guess, we will be using portworx. The last step we need to do is specify which components of CloudPak for Data we want to install. I will select Data Visualization and Watson Knowledge Catalog. Finally, the moment has come where we can kick of the installation. Read and confirm the license agreement and click install. This will kick on an IBM Cloud Schematics installation process that depending on the components of Cloud Pak for Data you selected, will complete in about an hour. 5 -- Validating Cloud Pak for Data Installation The first thing to check is did the schematics installation report that it was successful. To check this, navigate to schematics and then workspaces from the IBM Cloud console. Look for a workspace named ibm-cp-datacore ... and verify the state is active with a green circle. The last thing to check is can you launch the Cloud Pak for Data console. From the IBM Cloud console, navigate to your list of clusters and click on the satellite cluster that you installed CloudPak for Data on. Then click on Openshift web console. From the OpenShift console, click on Networking and then Routes. Select the CP4D project and you should see a route like below. Click on the url in the location ... and tada ... you should see the Cloud Pak for Data console pop up. You can log into Cloud Pak for Data with the default username = admin and password=password. Congratulations, you can now start using CloudPak for Data.","title":"Satellite cp4d"},{"location":"cp4d/satellite-cp4d/#install-cloud-pak-for-data-on-ibm-cloud-satellite","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com )","title":"Install Cloud Pak for Data on IBM Cloud Satellite"},{"location":"cp4d/satellite-cp4d/#1-introduction","text":"In this section, we will be provisioning Cloud Pak for Data on our satellite location. One of the most important parts of Cloud Pak for Data is the storage that you will use in your cluster. To get the best performance for Cloud Pak for Data we will be creating Block storage in our VPC and then use Portworx Software Defined Storage, provisioned from the IBM Cloud Catalog, to handle the storage needs for Cloud Pak for Data. By default, when you create an IBM Cloud Managed OpenShift cluster on a Satellite location, the internal image registry is create using emptyDir. This means that images in your cluster will be stored locally on the image registry pod itself. If the pod goes down, you will lose your images. The reason this is initially created like this is to give you flexibility to use the backing of your choice for your image registry. With your satellite location being on prem, at the edge, or maybe a third-party cloud provider there are many options you can choose from meeting your business requirements. A great choice to use for an image registry is IBM Cloud Object Storage which we will setup to use as our image registry backing.","title":"1 - Introduction"},{"location":"cp4d/satellite-cp4d/#2-image-registry","text":"When you install Cloud Pak for Data, the installer is going to copy the images Cloud Pak for Data will use to your local image registry. This is done to greatly improve the speed of the installation process. The first thing we are going to do is create an IBM Cloud Object Storage instance and bucket. Note: if you already have an instance of IBM Cloud Object Storage you can skip to section 2.2","title":"2 - Image Registry"},{"location":"cp4d/satellite-cp4d/#21-provision-ibm-cloud-object-storage","text":"To provision IBM Cloud Object Storage, from the cloud.ibm.com portal, click on Catalog, search for Object Storage and then click on the Object Storage tile. On the next screen, you will want to give the instance of IBM Cloud Object Storage a meaningful name, I will use Cloud Object Storage-Satellite and choose the resource group where your satellite resources are to location to keep things organized.","title":"2.1 Provision IBM Cloud Object Storage"},{"location":"cp4d/satellite-cp4d/#22-create-a-bucket-for-your-image-repository","text":"The next thing we need to do, is create a bucket for our image registry. This bucket needs to have a couple specific settings so please make sure to closely follow the guide here. From your cloud object storage instance, click on Buckets and then Create bucket. Next, click on Customize your bucket: On the next screen, name your bucket something meaningful, I will use sat-cluster-image-registry-kmc. Note: the name of your bucket must be unique in the region where you are creating it, so you may want to use your initials like I have. Select Regional for resiliency, Location: us-east and then standard as the storage class. Note: With the exception of location, this should be whatever region is closest to your satellite location, it is important to select the values exactly as indicated. After entering these settings, click on Create Bucket . Now that we have created a bucket, the next step is to create Service Credentials so that our OpenShift cluster can talk to our instance of Cloud Object Storage to read and write images to the bucket we created. On the left-hand navigation pane, select Service Credentials and then click on New Credential . On the next screen, give your credentials a meaningful name, I will choose Service-credentials-satellite-registry , role should be Write and turn on HMAC . On the next screen, note down the apikey for the Cloud Object Storage Instance, the Access Key and the Secret Access Key. Make sure not to share this with anyone ... by the time anyone reads these I will have deleted these keys.","title":"2.2 Create a Bucket for your Image Repository"},{"location":"cp4d/satellite-cp4d/#23-configure-openshift-to-use-object-storage-for-the-image-registry","text":"Next, we need to create a secret for our image registry to talk to Cloud Object Storage. Start your terminal, log into IBM Cloud and your cluster. ibmcloud login --apikey= ... not the Object Storage API Key ibmcloud ks cluster config --cluster --admin Change the following command to use oc create secret generic image-registry-private-configuration-user --from-literal=REGISTRY_STORAGE_S3_ACCESSKEY= --from-literal=REGISTRY_STORAGE_S3_SECRETKEY= --namespace openshift-image-registry Now that we have our secret configured, we need to update the configuration of our image registry to point to the object storage instance and bucket we created. The easiest way to do this, is through the OpenShift web console. From cloud.ibm.com navigate to your satellite cluster and then click on OpenShift web console. Once the OpenShift console opens, click on Search , search for ' Config ' and the click on the Config -- imageregistry.operator.openshift.io ... On the next screen, click on cluster. Click on YAML and then scroll down until you see this section: managementState: Removed proxy: http: '' https: '' noProxy: '' httpSecret: dAagViLyMeJodISdQpqcXtodpd6c6ojGyZeGEFnKTjhvpsalEs6vF33Hz5iSldS6 storage: {} We need to make changes to the managementState and the storage lines. *Note -- when you make these changes, you may find you get a warning that object changed and you will need to reload it before you can make changes. You may need to try these a couple of times. One tip I found is change the managementState first and then go back and change storage. What you will need to do, is change managementState to Managed: managementState: Managed and under storage enter the following with your bucket name: storage: s3: bucket: sat-cluster-image-registry-kmc region: us-east-standard regionEndpoint: 'https://s3.us-east.cloud-object-storage.appdomain.cloud' virtualHostedStyle: false After entering these settings, click Save and then Reload. You should see the YAML has been updated with the settings you entered. If you switch to the details page and scroll down, you should see a message that the S3 bucket exists: If you don't see this verify you entered your object storage secrets correctly and try to edit the config yaml again. If it fails again, delete the config and start over. When you delete the config, a new one will top up a couple of seconds later. One additional check we can do to make sure the image registry really is configured, is looking at the image registry pod. To find out if the registry is running as it should, click on Workload and the Pods . Under project , search for and select openshift-image-registry and click on the image-registry pod. On the next screen, click on the Environment tab make sure you see that your object storage is indicated. If you don't see object storage values like below, then try updating the config again.","title":"2.3 Configure OpenShift to use Object Storage for the Image Registry"},{"location":"cp4d/satellite-cp4d/#3-configure-storage","text":"","title":"3 -- Configure Storage"},{"location":"cp4d/satellite-cp4d/#31-provision-block-storage","text":"Not surprisingly from the name, Cloud Pak for Data requires storage to store data to perform analytics among other things. With our cluster running on a Virtual Private Cloud, the best choice of storage is Block storage. To create block storage on IBM Cloud, from the VPC, click on Storage , Block storage volumes and then click Create . We will need to create one block storage volume for each worker node. Starting with zone 1 worker 1, enter the following settings: Name: zone1-worker1-volume Location: Dallas1 Scrolling down further, under Volume profile , select Custom and then enter 6000 for IOPS and 500 for the size. Finally, click Create Volume. Repeat the same steps for all the other worker nodes. As a tip: you can also create these block volumes with the CLI using the following command: ibmcloud is volume-create zone2-worker1-vol custom us-south-2 --iops 6000 --capacity 500","title":"3.1 Provision Block Storage"},{"location":"cp4d/satellite-cp4d/#32-attach-the-block-volumes-to-your-instances","text":"Now that we have block volumes created for all our worker nodes we need to attach them. To attach the block volumes, from the VPC Menu, select Virtual Server Instances. For each worker node instance, click on the name. Scroll down to the Storage volumes section and click on Attach. On the next screen, select the block volume for the corresponding Virtual Server Instance and click save. Repeat the same process for the remaining worker nodes.","title":"3.2 Attach the Block Volumes to your instances"},{"location":"cp4d/satellite-cp4d/#32-provision-portworx","text":"The last step to prepare for Cloud Pak for Data installation is to provision an instance of portworx and since our cluster is a satellite cluster we can do this with the IBM Cloud Catalog. When you install portworx, you have two options to use for the portworx configuration. You can use either the internal kvdb that portworx provides or use an external etcd such as IBM Cloud Databases for etcd. From experience, I highly recommend to use an external etcd to use for you portworx kvdb. The reason for this is if you use the internal kvdb and you reload or replace one your worker nodes, your portworx configuration will fail. While you won't lose any data, you will have to go through a rather painful process of fixing your portworx configuration. It only takes about 5 extra minutes to setup an external etcd system and you get a piece of mind that your portworx configuration will be highly available and rock solid.","title":"3.2 Provision Portworx"},{"location":"cp4d/satellite-cp4d/#322-provision-ibm-cloud-databases-for-etcd","text":"To install IBM Cloud Databases for etcd, from the cloud.ibm.com console, click on catalog, search for etcd and then click on the Databases for etcd tile. The first thing we need to do is to specify a location for our IBM Cloud databases for etcd to run. For best performance, you will want to select the location that is nearest is your satellite location. Next, we need to enter the following specific settings for etcd to support portworx. Start by giving your etcd instance a meaningful name, I will use Databases for etcd-px-satellite and choose the same resource group your cluster is in. Next, select the following options for etcd and then click Create to create the instance of etcd. Initial memory allocation: 8GB/member (24GB total) Initial disk allocation: 128GB/member (384GB total) Initial CPU allocation: 3 dedicated cores/member (9 cores total) Database version: 3.3 The next think we need to do is generate service credentials for etcd so that portworx can use this etcd instance. After your instance is created it, click on it and the click on service credentials from the menu and finally click on New Credential. {width=\"6.5in\" height=\"3.43125in\"} On the next screen, give your credentials a meaningful name, I will use Service Credentials-px-etcd . Next, we need to retrieve a couple of values from the service credentials we just created. The three values that we need to copy are: certificate_base64 username password We we are going to do is create a Kubernetes secret with these values. The certificate value we can us as-is. The username and password we will need to base64 encode. To do so, start your terminal and enter the following command: echo -n | base64 Repeat the same steps to base64 encode the password. Now that we have the values we need, we can create a Kubernetes secret with these values. Create a new file, I will just name it px-secrets.yaml with the values you just retrieved. apiVersion: v1 kind: Secret metadata: name: px-etcd-certs namespace: kube-system type: Opaque data: ca.pem: \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUREekNDQWZlZ0F3SUJBZ0lKQU5FSDU4eTIva3pITUEwR0NTcUdTSWIzRFFFQkN3VUFNQjR4SERBYUJnTlYKQkFNTUUwbENUU0JEYkc5MVpDQkVZWFJoWW1GelpYTXdIaGNOTVRnd05qSTFNVFF5T1RBd1doY05Namd3TmpJeQpNVFF5T1RBd1dqQWVNUnd3R2dZRFZRUUREQk5KUWswZ1EyeHZkV1FnUkdGMFlXSmhjMlZ6TUlJQklqQU5CZ2txCmhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBOGxwYVFHemNGZEdxZU1sbXFqZmZNUHBJUWhxcGQ4cUoKUHIzYklrclhKYlRjSko5dUlja1NVY0NqdzRaL3JTZzhublQxM1NDY09sKzF0bys3a2RNaVU4cU9XS2ljZVlaNQp5K3laWWZDa0dhaVpWZmF6UUJtNDV6QnRGV3YrQUIvOGhmQ1RkTkY3Vlk0c3BhQTNvQkUyYVM3T0FOTlNSWlNLCnB3eTI0SVVnVWNJTEpXK21jdlc4MFZ4K0dYUmZEOVl0dDZQUkpnQmhZdVVCcGd6dm5nbUNNR0JuK2wyS05pU2YKd2VvdllEQ0Q2Vm5nbDIrNlc5UUZBRnRXWFdnRjNpRFFENW5sL240bXJpcE1TWDZVRy9uNjY1N3U3VERkZ2t2QQoxZUtJMkZMellLcG9LQmU1cmNuck03bkhnTmMvbkNkRXM1SmVjSGIxZEh2MVFmUG02cHpJeHdJREFRQUJvMUF3ClRqQWRCZ05WSFE0RUZnUVVLMytYWm8xd3lLcytERW9ZWGJIcnV3U3BYamd3SHdZRFZSMGpCQmd3Rm9BVUszK1gKWm8xd3lLcytERW9ZWGJIcnV3U3BYamd3REFZRFZSMFRCQVV3QXdFQi96QU5CZ2txaGtpRzl3MEJBUXNGQUFPQwpBUUVBSmY1ZHZselVwcWFpeDI2cUpFdXFGRzBJUDU3UVFJNVRDUko2WHQvc3VwUkhvNjNlRHZLdzh6Ujd0bFdRCmxWNVAwTjJ4d3VTbDlacUFKdDcvay8zWmVCK25Zd1BveU8zS3ZLdkFUdW5SdmxQQm40RldWWGVhUHNHKzdmaFMKcXNlam1reW9uWXc3N0hSekdPekpINFpnOFVONm1mcGJhV1NzeWFFeHZxa25DcDlTb1RRUDNENjdBeldxYjF6WQpkb3FxZ0dJWjJueENrcDUvRlh4Ri9UTWI1NXZ0ZVRRd2ZnQnk2MGpWVmtiRjdlVk9XQ3YwS2FOSFBGNWhycWJOCmkrM1hqSjcvcGVGM3hNdlRNb3kzNURjVDNFMlplU1Zqb3VaczE1Tzkwa0kzazJkYVMyT0hKQUJXMHZTajRuTHoKK1BRenAvQjljUW1PTzhkQ2UwNDlRM29hVUE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCgo=\" username: \"aWJtX2Nsb3VkX2UzNzcxNDZlXzE1MDZfNDdhZF9hZGFjX2JiMjI0YzlhMjViYQ==\" password: \"ZmQzZTljNDcwOTliM2EzOTliNDVmMGYyY2YwMGE5NTEzYjJmZTI0ZGI3NTVjODAwYjNmYw==\" The last step we need to do before we install portworx is creating the secret in our cluster. After logging into your cluster from the command line, run: oc create -f px-secret.yaml","title":"3.2.2 Provision IBM Cloud Databases for etcd"},{"location":"cp4d/satellite-cp4d/#323-provision-portworx-from-the-ibm-cloud-catalog","text":"From the IBM Cloud console, click on Catalog, search for Portworx and then click on the Portworx Enterprise tile. Start by selecting the region that is connected to your satellite location. I am using us-east Washington DC. For pricing plan, choose the Enterprise plan. For setting, start by giving your portworx instance a meaningful name such as Portworx Enterprise-satellite and choose the same resource group you have been using for all your resources. Enter your cloud API key ( note: you need to enter this API key before you are able to select the cluster to install portworx in). Finally, in this section give a unique name for portworx cluster ( note this is not a kubernetes cluster but rather a portworx storage cluster that runs inside your openshift cluster ). I will use px-cluster. Next, we need to get our endpoint for our etcd service. In a new window, navigate back to your service credentials for etcd instance and copy the endpoint. Enter the following settings: For etcd endpoint enter etcd: Select the satellite cluster you want to install portworx on. For secret name, enter the name of the secret you created. If you followed my yaml example the secret name is px-etcd-certs After entering all of these settings click on Create .","title":"3.2.3 Provision Portworx from the IBM Cloud Catalog"},{"location":"cp4d/satellite-cp4d/#324-check-portworx-installation","text":"It is always a good idea to make sure portworx has been successfully installed on your cluster before you proceed. To do so, log into your cluster through your terminal. After logged in, change to the kube-system project. oc project kube-system Search for portworx pods and note the name of one the pods that starts with portworx... Next enter the following command substituting the name of the portworx pod you just noted. kubectl exec portworx-7czms -it -n kube-system -- /opt/pwx/bin/pxctl status After entering that command, you should see output like the above. Check to make sure the status is online and that you have a storage node for each of your workers.","title":"3.2.4 Check Portworx installation"},{"location":"cp4d/satellite-cp4d/#4-provision-cloud-pak-for-data","text":"At this point, we have completed all the required pre-reqs to now install Cloud Pak for Data through the IBM Cloud Catalog. To get started, from the IBM Cloud catalog, search for Cloud Pak for Data and then click on the tile. On the next screen, select the satellite cluster you want to install Cloud Pak for Data on, and create a new project for cloud pak for data, I like to use cp4d. Scroll down to the preinstallation section and click on Run Script. In a couple of minutes, you will see a green box showing the preinstallation script was successfully ran. Next, we need to specify which storage class to use. As you can probably guess, we will be using portworx. The last step we need to do is specify which components of CloudPak for Data we want to install. I will select Data Visualization and Watson Knowledge Catalog. Finally, the moment has come where we can kick of the installation. Read and confirm the license agreement and click install. This will kick on an IBM Cloud Schematics installation process that depending on the components of Cloud Pak for Data you selected, will complete in about an hour.","title":"4 -- Provision Cloud Pak for Data"},{"location":"cp4d/satellite-cp4d/#5-validating-cloud-pak-for-data-installation","text":"The first thing to check is did the schematics installation report that it was successful. To check this, navigate to schematics and then workspaces from the IBM Cloud console. Look for a workspace named ibm-cp-datacore ... and verify the state is active with a green circle. The last thing to check is can you launch the Cloud Pak for Data console. From the IBM Cloud console, navigate to your list of clusters and click on the satellite cluster that you installed CloudPak for Data on. Then click on Openshift web console. From the OpenShift console, click on Networking and then Routes. Select the CP4D project and you should see a route like below. Click on the url in the location ... and tada ... you should see the Cloud Pak for Data console pop up. You can log into Cloud Pak for Data with the default username = admin and password=password. Congratulations, you can now start using CloudPak for Data.","title":"5 -- Validating Cloud Pak for Data Installation"},{"location":"lb/satellite-lb/","text":"Exposing an OpenShift application to the Internet from a \u2018private\u2019 Satellite Cluster using a Load Balancer Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) Let's say you have deployed a RedHat OpenShift Cluster via IBM Cloud Satellite in a private isolated network in your datacenter and now you have deployed certain applications on this OpenShift Cluster which are required to be exposed to the public Internet. According to the current design the only way it is possible to expose the application to the public Internet is either you expose your whole satellite location to the Internet or use networking infrastructure such as (load balancer, http/https/TLS proxy etc.). Exposing the whole satellite location brings up a huge security concern i.e. anybody from the outside world can access you satellite control plane in the datacenter or the OpenShift worker nodes themselves and this is not ideal for any enterprise. Hence using networking infrastructure make much more sense for both security and operational points to expose applications to the Internet. This involves having a networking device outside of the cluster and configuring the load balancer to access a NodePort service on your OpenShift Cluster. Not only will you find this method more secure, it also scales better. In tutorial we will show you how to NAT the traffic coming from the Internet to your internal private network via a load balancer so that your application is accessible via the internet. Note: This step-by-step tutorial have been performed on IBM Cloud, but steps should be similar on other public cloud providers and on-prem. Create a load balancer service with your cloud provider. IBM Cloud Example: From the IBM Cloud menu, navigate to VPC Infrastructure and under Network , select Load Balancers , and click Create . Configure the Load Balancer Give the load balancer a name , select Application Load Balancer , select the Region where your satellite hosts are, select your virtual private cloud your hosts are in, and finally select all subnets for your VPC. Create a backend pool In OpenShift, get the nodeport of the service you want to expose to the Internet. Example to Test: Create a new openshift application oc new-app openshift/hello-openshift This creates a pod and a cluster ip service. Edit the service, search for ClusterIP and change it to NodePort. Save the service. oc edit svc hello-openshift Note the port of the service. In this case, we want to create a load balancer for the service running on port 8080 which maps to port 30268 in the cluster. Create a backend pool Back on the create load balancer page, click on New Pool in the backend pool section. Following the above example, we will use the name hello-openshift and for Health Port, but the port number we got in the previous step ... in this case 30268. Attach Virtual Hosts to the Backend Pool. Under the backend pool section, click on attach . On the next screen select the first subnet, and then select the first worker node instance, and use the same port number ( 30268 in our case ). Click add and repeat the same steps for every subnet and every worker node in the cluster. *Important note -- when you add or remove worker nodes in your cluster, will need to go back to this backend pool and either add the new worker node or remove it from this backend pool. After entering all the worker nodes, they should all appear in attached instances. Create Front-end Listener Under front-end listeners, click on New listener . On the next screen, enter the node port from your service ( in the example above 30280 ), select your backend pool, and then enter 15000 as the maximum connections, and then click save. Create the load balancer On the panel on the right hand side of the screen, click on Create Load Balancer. Get the load balancer host name The load balancer will take a few minutes to create. After it is created, you can view the hostname from the overview page. Test the load balancer If you are following the example in this document, you can curl the hostname and it should tell you \"Hello Openshift\" Note, it can take a couple of minutes for DNS to be updated. If you want to test right away run host \\<hostname\\> This will return 2 IPs, like below that you can then curl instead of the hostname if you want to test right away.","title":"Satellite lb"},{"location":"lb/satellite-lb/#exposing-an-openshift-application-to-the-internet-from-a-private-satellite-cluster-using-a-load-balancer","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) Let's say you have deployed a RedHat OpenShift Cluster via IBM Cloud Satellite in a private isolated network in your datacenter and now you have deployed certain applications on this OpenShift Cluster which are required to be exposed to the public Internet. According to the current design the only way it is possible to expose the application to the public Internet is either you expose your whole satellite location to the Internet or use networking infrastructure such as (load balancer, http/https/TLS proxy etc.). Exposing the whole satellite location brings up a huge security concern i.e. anybody from the outside world can access you satellite control plane in the datacenter or the OpenShift worker nodes themselves and this is not ideal for any enterprise. Hence using networking infrastructure make much more sense for both security and operational points to expose applications to the Internet. This involves having a networking device outside of the cluster and configuring the load balancer to access a NodePort service on your OpenShift Cluster. Not only will you find this method more secure, it also scales better. In tutorial we will show you how to NAT the traffic coming from the Internet to your internal private network via a load balancer so that your application is accessible via the internet. Note: This step-by-step tutorial have been performed on IBM Cloud, but steps should be similar on other public cloud providers and on-prem.","title":"Exposing an OpenShift application to the Internet from a \u2018private\u2019 Satellite Cluster using a Load Balancer"},{"location":"lb/satellite-lb/#create-a-load-balancer-service-with-your-cloud-provider","text":"IBM Cloud Example: From the IBM Cloud menu, navigate to VPC Infrastructure and under Network , select Load Balancers , and click Create .","title":"Create a load balancer service with your cloud provider."},{"location":"lb/satellite-lb/#configure-the-load-balancer","text":"Give the load balancer a name , select Application Load Balancer , select the Region where your satellite hosts are, select your virtual private cloud your hosts are in, and finally select all subnets for your VPC.","title":"Configure the Load Balancer"},{"location":"lb/satellite-lb/#create-a-backend-pool","text":"In OpenShift, get the nodeport of the service you want to expose to the Internet. Example to Test: Create a new openshift application oc new-app openshift/hello-openshift This creates a pod and a cluster ip service. Edit the service, search for ClusterIP and change it to NodePort. Save the service. oc edit svc hello-openshift Note the port of the service. In this case, we want to create a load balancer for the service running on port 8080 which maps to port 30268 in the cluster.","title":"Create a backend pool"},{"location":"lb/satellite-lb/#create-a-backend-pool_1","text":"Back on the create load balancer page, click on New Pool in the backend pool section. Following the above example, we will use the name hello-openshift and for Health Port, but the port number we got in the previous step ... in this case 30268. Attach Virtual Hosts to the Backend Pool. Under the backend pool section, click on attach . On the next screen select the first subnet, and then select the first worker node instance, and use the same port number ( 30268 in our case ). Click add and repeat the same steps for every subnet and every worker node in the cluster. *Important note -- when you add or remove worker nodes in your cluster, will need to go back to this backend pool and either add the new worker node or remove it from this backend pool. After entering all the worker nodes, they should all appear in attached instances.","title":"Create a backend pool"},{"location":"lb/satellite-lb/#create-front-end-listener","text":"Under front-end listeners, click on New listener . On the next screen, enter the node port from your service ( in the example above 30280 ), select your backend pool, and then enter 15000 as the maximum connections, and then click save.","title":"Create Front-end Listener"},{"location":"lb/satellite-lb/#create-the-load-balancer","text":"On the panel on the right hand side of the screen, click on Create Load Balancer.","title":"Create the load balancer"},{"location":"lb/satellite-lb/#get-the-load-balancer-host-name","text":"The load balancer will take a few minutes to create. After it is created, you can view the hostname from the overview page.","title":"Get the load balancer host name"},{"location":"lb/satellite-lb/#test-the-load-balancer","text":"If you are following the example in this document, you can curl the hostname and it should tell you \"Hello Openshift\" Note, it can take a couple of minutes for DNS to be updated. If you want to test right away run host \\<hostname\\> This will return 2 IPs, like below that you can then curl instead of the hostname if you want to test right away.","title":"Test the load balancer"},{"location":"satellite/satellite/","text":"Deploy to a Remote Location with IBM Cloud Satellite Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) 1 - Introduction In the next few sections, we will be setting up and provisioning our zero to cloud native app to run on a remote location by leveraging IBM Cloud Satellite. IBM Cloud Satellite allows you to deploy IBM Cloud services anywhere you need them and is delivered as service through a single pane of glass. In this series, we will be deploying IBM Cloud Satellite in a private only Virtual Private Cloud on IBM Cloud with no connectivity to the Internet. This will simulate a realistic use case in deploying IBM Cloud to a private location. While this tutorial series will walk through step by step in setting up a private virtual private cloud on IBM Cloud 2 -- Provision IBM Cloud Satellite The first step to get started with IBM Cloud Satellite is to provision a Satellite location. A location are the central part of your satellite deployment and is where all of your IBM Cloud Services will run. 2.1 Create a Satellite Location To get started in provisioning your satellite location, from the IBM Cloud menu navigate to and select Satellite. Next, get started by clicking Create a Satellite location. Give your satellite location a meaningful name such as satellite-zero-to-cloud-native, select the IBM Cloud location that will manage your satellite location, I will select Washington DC, and click Create Location. This will bring you to a screen that will show you satellite location is being created. This takes a couple of minutes. After our location is created, we will need to add hosts to the location. These hosts can be anywhere, from onPrem, to a cloud provider such as AWS, Azure, GCP, or even IBM Cloud. The hosts can be physical or virtual, the choice is yours. There are minimum hardware requirements for your satellite hosts that you can view here: https://cloud.ibm.com/docs/satellite?topic=satellite-host-reqs 2.2 Download Attach Hosts Script Our satellite location will have two types of hosts which will be VPC instances. Hosts for the control plan and hosts for our IBM Cloud Managed OpenShift worker nodes. As you will see after your infrastructure hosts are provisioned we will need to run a script to attach those instances to our satellite location. A best practice is to include those scripts in the instance template we use to build the instances for our satellite location. To get the script to attach hosts to the satellite location, click on Hosts from the satellite page. Then select Attach host On the next screen, add a tag for the control plane instances. Entering meaningful tags is another best practice that will allow us to quickly find and identify specific hosts. Label: host:02cn-control-plane Filename: attachHost-satellite-02cn-control-plane.sh Note: A best practice is to have different labels for control plane and worker node instances, so it is easy to tell them apart. After entering these settings, click Download Script . Repeat the same process of clicking Attach host and downloading a script for the worker nodes with these values: Label: host:02cn-worker Filename: attachHost-satellite-02cn-worker.sh 3 - Provision Infrastructure To use a Satellite location, you need to provide infrastructure for Satellite to run on it. You can deploy Satellite wherever you want, it could be on-premises, on any cloud provider, or even at the edge. In section 14A IBM Cloud VPC Infrastructure for Satellite , there are instructions to create infrastructure leveraging IBM Cloud Virtual Private Cloud. If you prefer to use a different cloud provider or even an on-premises infrastructure, then that is more than fine. The remaining steps of this tutorial series will work regardless of where you the infrastructure is deployed. That is the beauty of IBM Cloud Satellite, it runs wherever you are. Click the link below to setup IBM Cloud VPC Infrastructure for your Satellite location: IBM Cloud VPC Infrastructure for Satellite 4 Setup your Satellite Location Once you have all of your infrastructure provisioned and ready, the first thing you will want to do is deploy an OpenShift Cluster. 4.1 Assign Control Plane Hosts Before we can deploy an OpenShift cluster, we need to setup up our control plan by assigning the hosts we created for the control plane to the control plane. While in the IBM Cloud Console, from the satellite menu click on Locations and then your satellite-zero-to-cloud-native location. On next screen, click on hosts. This will show you a list of all the hosts that are assigned to your location. When you provisioned the VSIs, the attachHosts script that we ran is what has registered your hosts with your satellite location. On the next screen, you will see that all of your hosts are Ready and Unassigned. Next to each 'control plane' host, click Assign host by clicking the three dots. On the next screen you assign the host to a cluster. Make the following assignments: satellite-control-plane-dal1 = us-east-1 satellite-control-plane-dal2 = us-east-2 satellite-control-plane-dal3 = us-east-3 Assigning hosts takes a couple of minutes. When the assignment is complete, you will see the status of the hosts change as follows: 4.2 Create IBM Cloud Managed OpenShift Cluster Before trying to create a cluster, you need to make sure your Satellite location and infrastructure control plane is ready to deploy. Navigating to your satellite location, ensure that the control plan hosts are in Healthy State and the overall Satellite location is normal. To provision a RedHat OpenShift on IBM Cloud cluster, go to the IBM Cloud catalog, search for OpenShift, and click on the tile. On the next screen, enter the following information about your Satellite location to create a new cluster. Version: Select the most recent version of OpenShift . Infrastructure: Satellite Location -- Resource Group -- zero-to-cloud-native Location -- Satellite -- satellite-zero-to-cloud-native Cluster name: satellite-02cn After entering these settings, click create Cluster . This will go off and start building the master nodes of your cluster and takes about 20 minutes. While this is completing, navigate to the Overview page of your cluster and you will notice a couple of things. The Master Status will show Deploy in progress, this will change to Ready when the master nodes are completely deployed. The Worker Nodes section will indicate that you don't have any nodes yet. The next thing we will need to do is assign worker nodes to our cluster. 4.3 Assign Worker Nodes To assign worker nodes to our satellite cluster, navigate back to your satellite location and the hosts tab. Next to each worker node, click on Assign host. And select the cluster you created in the previous step and click Assign host. Repeat the same steps for all the worker nodes. This will register hosts that your IBM Cloud Managed OpenShift cluster will use as worker nodes. In about 10 minutes, you will find all your worker nodes in a Normal status and you can start using your cluster. 4.4 Create an OpenVPN Connection Because our cluster is on a private VPC with no Internet connectivity, we will need to create a VPN connection into our VPC. The instructions are rather long, so please refer to part 14B VPN Guide for detailed instructions on doing so. You can find instructions here on how to create a VPN Connection to IBM Cloud: VPN Guide 4.5 Enable the OpenShift Console There is one last step we need to perform so we can use the OpenShift console. This does require that you have successfully configured an OpenVPN connection into your VPC. To test your VPN connection has been successful, run the following commands: Log into IBM Cloud: ibmcloud login --apikey=\\<your cloud apikey\\> Target your cluster: ibmcloud ks cluster config -c satellite-02cn \\--admin *If you used a different cluster name, you will need to update satellite-02cn with that cluster name View your worker nodes: oc get nodes If you see a list of all your worker nodes like the following then your VPN connection is successful! ... if not, revisit the OpenVPN section. Now that we have verified our VPN connection was successful, we need to execute a couple more commands so that our OpenShift console works. These commands require calicoctl. If you don't have the calicoctl CLI installed on your system you can do so with the following command: brew install calicoctl Before we can launch the OpenShift console, we need to enable VXLAN encapsulation instead of the default IP in IP encapsulation. To do this, save the following yaml file. pool.yaml apiVersion: projectcalico.org/v3 kind: IPPool metadata: name: default-ipv4-ippool spec: blockSize: 26 cidr: 172.30.0.0/16 ipipMode: Never natOutgoing: true nodeSelector: all() vxlanMode: Always and run the following: ibmcloud ks cluster config \\--admin -c satellite-02cn export DATASTORE_TYPE=kubernetes calicoctl apply -f /path/to/pool.yaml Now for the moment of truth! Navigate to your satellite-02cn cluster in the IBM Cloud console and click on OpenShift web console . This will launch your OpenShift Console. Congratulations, you have now setup and configured a private satellite location with an OpenShift Cluster managed by IBM Cloud!","title":"Satellite"},{"location":"satellite/satellite/#deploy-to-a-remote-location-with-ibm-cloud-satellite","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com )","title":"Deploy to a Remote Location with IBM Cloud Satellite"},{"location":"satellite/satellite/#1-introduction","text":"In the next few sections, we will be setting up and provisioning our zero to cloud native app to run on a remote location by leveraging IBM Cloud Satellite. IBM Cloud Satellite allows you to deploy IBM Cloud services anywhere you need them and is delivered as service through a single pane of glass. In this series, we will be deploying IBM Cloud Satellite in a private only Virtual Private Cloud on IBM Cloud with no connectivity to the Internet. This will simulate a realistic use case in deploying IBM Cloud to a private location. While this tutorial series will walk through step by step in setting up a private virtual private cloud on IBM Cloud","title":"1 - Introduction"},{"location":"satellite/satellite/#2-provision-ibm-cloud-satellite","text":"The first step to get started with IBM Cloud Satellite is to provision a Satellite location. A location are the central part of your satellite deployment and is where all of your IBM Cloud Services will run.","title":"2 -- Provision IBM Cloud Satellite"},{"location":"satellite/satellite/#21-create-a-satellite-location","text":"To get started in provisioning your satellite location, from the IBM Cloud menu navigate to and select Satellite. Next, get started by clicking Create a Satellite location. Give your satellite location a meaningful name such as satellite-zero-to-cloud-native, select the IBM Cloud location that will manage your satellite location, I will select Washington DC, and click Create Location. This will bring you to a screen that will show you satellite location is being created. This takes a couple of minutes. After our location is created, we will need to add hosts to the location. These hosts can be anywhere, from onPrem, to a cloud provider such as AWS, Azure, GCP, or even IBM Cloud. The hosts can be physical or virtual, the choice is yours. There are minimum hardware requirements for your satellite hosts that you can view here: https://cloud.ibm.com/docs/satellite?topic=satellite-host-reqs","title":"2.1 Create a Satellite Location"},{"location":"satellite/satellite/#22-download-attach-hosts-script","text":"Our satellite location will have two types of hosts which will be VPC instances. Hosts for the control plan and hosts for our IBM Cloud Managed OpenShift worker nodes. As you will see after your infrastructure hosts are provisioned we will need to run a script to attach those instances to our satellite location. A best practice is to include those scripts in the instance template we use to build the instances for our satellite location. To get the script to attach hosts to the satellite location, click on Hosts from the satellite page. Then select Attach host On the next screen, add a tag for the control plane instances. Entering meaningful tags is another best practice that will allow us to quickly find and identify specific hosts. Label: host:02cn-control-plane Filename: attachHost-satellite-02cn-control-plane.sh Note: A best practice is to have different labels for control plane and worker node instances, so it is easy to tell them apart. After entering these settings, click Download Script . Repeat the same process of clicking Attach host and downloading a script for the worker nodes with these values: Label: host:02cn-worker Filename: attachHost-satellite-02cn-worker.sh","title":"2.2 Download Attach Hosts Script"},{"location":"satellite/satellite/#3-provision-infrastructure","text":"To use a Satellite location, you need to provide infrastructure for Satellite to run on it. You can deploy Satellite wherever you want, it could be on-premises, on any cloud provider, or even at the edge. In section 14A IBM Cloud VPC Infrastructure for Satellite , there are instructions to create infrastructure leveraging IBM Cloud Virtual Private Cloud. If you prefer to use a different cloud provider or even an on-premises infrastructure, then that is more than fine. The remaining steps of this tutorial series will work regardless of where you the infrastructure is deployed. That is the beauty of IBM Cloud Satellite, it runs wherever you are. Click the link below to setup IBM Cloud VPC Infrastructure for your Satellite location: IBM Cloud VPC Infrastructure for Satellite","title":"3 - Provision Infrastructure"},{"location":"satellite/satellite/#4-setup-your-satellite-location","text":"Once you have all of your infrastructure provisioned and ready, the first thing you will want to do is deploy an OpenShift Cluster.","title":"4 Setup your Satellite Location"},{"location":"satellite/satellite/#41-assign-control-plane-hosts","text":"Before we can deploy an OpenShift cluster, we need to setup up our control plan by assigning the hosts we created for the control plane to the control plane. While in the IBM Cloud Console, from the satellite menu click on Locations and then your satellite-zero-to-cloud-native location. On next screen, click on hosts. This will show you a list of all the hosts that are assigned to your location. When you provisioned the VSIs, the attachHosts script that we ran is what has registered your hosts with your satellite location. On the next screen, you will see that all of your hosts are Ready and Unassigned. Next to each 'control plane' host, click Assign host by clicking the three dots. On the next screen you assign the host to a cluster. Make the following assignments: satellite-control-plane-dal1 = us-east-1 satellite-control-plane-dal2 = us-east-2 satellite-control-plane-dal3 = us-east-3 Assigning hosts takes a couple of minutes. When the assignment is complete, you will see the status of the hosts change as follows:","title":"4.1 Assign Control Plane Hosts"},{"location":"satellite/satellite/#42-create-ibm-cloud-managed-openshift-cluster","text":"Before trying to create a cluster, you need to make sure your Satellite location and infrastructure control plane is ready to deploy. Navigating to your satellite location, ensure that the control plan hosts are in Healthy State and the overall Satellite location is normal. To provision a RedHat OpenShift on IBM Cloud cluster, go to the IBM Cloud catalog, search for OpenShift, and click on the tile. On the next screen, enter the following information about your Satellite location to create a new cluster. Version: Select the most recent version of OpenShift . Infrastructure: Satellite Location -- Resource Group -- zero-to-cloud-native Location -- Satellite -- satellite-zero-to-cloud-native Cluster name: satellite-02cn After entering these settings, click create Cluster . This will go off and start building the master nodes of your cluster and takes about 20 minutes. While this is completing, navigate to the Overview page of your cluster and you will notice a couple of things. The Master Status will show Deploy in progress, this will change to Ready when the master nodes are completely deployed. The Worker Nodes section will indicate that you don't have any nodes yet. The next thing we will need to do is assign worker nodes to our cluster.","title":"4.2 Create IBM Cloud Managed OpenShift Cluster"},{"location":"satellite/satellite/#43-assign-worker-nodes","text":"To assign worker nodes to our satellite cluster, navigate back to your satellite location and the hosts tab. Next to each worker node, click on Assign host. And select the cluster you created in the previous step and click Assign host. Repeat the same steps for all the worker nodes. This will register hosts that your IBM Cloud Managed OpenShift cluster will use as worker nodes. In about 10 minutes, you will find all your worker nodes in a Normal status and you can start using your cluster.","title":"4.3 Assign Worker Nodes"},{"location":"satellite/satellite/#44-create-an-openvpn-connection","text":"Because our cluster is on a private VPC with no Internet connectivity, we will need to create a VPN connection into our VPC. The instructions are rather long, so please refer to part 14B VPN Guide for detailed instructions on doing so. You can find instructions here on how to create a VPN Connection to IBM Cloud: VPN Guide","title":"4.4 Create an OpenVPN Connection"},{"location":"satellite/satellite/#45-enable-the-openshift-console","text":"There is one last step we need to perform so we can use the OpenShift console. This does require that you have successfully configured an OpenVPN connection into your VPC. To test your VPN connection has been successful, run the following commands: Log into IBM Cloud: ibmcloud login --apikey=\\<your cloud apikey\\> Target your cluster: ibmcloud ks cluster config -c satellite-02cn \\--admin *If you used a different cluster name, you will need to update satellite-02cn with that cluster name View your worker nodes: oc get nodes If you see a list of all your worker nodes like the following then your VPN connection is successful! ... if not, revisit the OpenVPN section. Now that we have verified our VPN connection was successful, we need to execute a couple more commands so that our OpenShift console works. These commands require calicoctl. If you don't have the calicoctl CLI installed on your system you can do so with the following command: brew install calicoctl Before we can launch the OpenShift console, we need to enable VXLAN encapsulation instead of the default IP in IP encapsulation. To do this, save the following yaml file. pool.yaml apiVersion: projectcalico.org/v3 kind: IPPool metadata: name: default-ipv4-ippool spec: blockSize: 26 cidr: 172.30.0.0/16 ipipMode: Never natOutgoing: true nodeSelector: all() vxlanMode: Always and run the following: ibmcloud ks cluster config \\--admin -c satellite-02cn export DATASTORE_TYPE=kubernetes calicoctl apply -f /path/to/pool.yaml Now for the moment of truth! Navigate to your satellite-02cn cluster in the IBM Cloud console and click on OpenShift web console . This will launch your OpenShift Console. Congratulations, you have now setup and configured a private satellite location with an OpenShift Cluster managed by IBM Cloud!","title":"4.5 Enable the OpenShift Console"},{"location":"vpc/vpc/","text":"Deploy Satellite Infrastructure on IBM Cloud VPC Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) 1 - Introduction As you learned in the previous section, IBM Cloud Satellite can be deployed anywhere that you want from onPrem, to a cloud provider such as AWS, Azure, GCP, to the edge, or even on IBM Cloud. The instructions here will show you how to provision infrastructure on IBM Cloud VPC. While certain other options and providers will have different instructions the same concepts will apply. To simulate a more realistic environment, we will be deploying a private only Virtual Private Cloud with no Internet Connectivity. 2 -- Provision IBM Cloud Virtual Private Cloud 2.1 Edit Attach Host Scripts In Section 14, when you first created your satellite location, you downloaded two 'attachHosts' scripts. These attachHost scripts are what tells IBM Cloud Satellite to use these hosts in your Satellite location. Before the attach host script can be ran, we need to run two commands on each instance to ensure the correct RedHat packages are installed. To automate running these scripts when the attach host script is ran, we need to edit both attach host scripts to include these commands. Open you code editor and open either attachHost file you downloaded. Look in the file for a line that starts with API_URL and add the following three lines of code: # enabling dependencies required by satellite subscription-manager refresh subscription-manager repos --enable=* Repeat the same steps for the other attachHost file. 2.2 Create a VPC Infrastructure for the Satellite Control Plane From your IBM Cloud menu, navigate to VPC Infrastructure and then select VPCs. To simulate a remote location, we will be creating a new private only VPC meaning there will be no connectivity outside of our VPC. From the Virtual Private Cloud page, click Create. Enter a name of the VPC, I will be using zero-to-cloud-native-satellite-vpc and select your zero-to-cloud-native resource group. Keep the remaining default settings and scroll down to New subnet for VPC. We will be created a multizone region across Dallas for our Satellite location. This means we will need to create a subnet for each zone. Starting with Dallas 1, give your subnet a meaningful name so you can find it later; I will be using satellite-02cn-dal1 and the zero-to-cloud-native resource group. Select Dallas1 as the location. Make sure to attach the Public Gateway attached. You can remove this later, but we need this enabled for setup and configuration. Keep the remaining settings as-is and click Create virtual private cloud . Next up, we need to create the two other subnets in Dallas 2 and Dallas 3 for our multizone location. To do so, from the IBM Cloud Menu under VPC Infrastructure, click on Subnets. On the next screen, click Create. Give you subnet for Dallas 2 a name, I will be using satellite-02cn-dal2, select the name of your virtual private cloud which should be zero-to-cloud-native-satellite-vpc, and the zero-to-cloud-native resource group. The location for this subnet should be Dallas 2. After entering all of these settings click on Create Subnet. Repeat the same steps to create a final subnet in Dallas 3. {width=\"6.5in\" height=\"2.25in\"} 3 Create VPC Infrastructure The first step in creating your satellite location is to provision infrastructure that your satellite location will use. In this tutorial we will be provisioning infrastructure in a VPC for both the control plane and the worker nodes for our IBM Cloud Managed OpenShift cluster. 3.1 VPC Infrastructure for the Satellite Control Plane We will start by provisioning the VPC infrastructure for the control plane. You can view this control plane as the master nodes for the IBM Cloud Managed OpenShift cluster will be creating. 3.1.1 VPC InstanceTemplate Now that we have a virtual private cloud configured with subnets, we can add hosts for the Satellite control plane to our VPC. The best way to create these VPC instances is to use an Instance Template. A VPC instance template is used to define instance details for provisioning our virtual servers for the control plan. This will enable us to quickly create consistent images for our control plane. To create an instance template, from the IBM Cloud menu, under VPC Infrastructure, expand Auto scale and then select Instance templates . On the next screen, click on Create to create your first instance template. We will be creating a template for each zone for our control plane. Starting with Dallas 1, give the template a meaningful name, I will use satellite-02cn-control-plane-dal1 . Select your zero-to-cloud-native-satellite-vpc VPC and the zero-cloud-native resource group. This template will be for Dallas 1 so also select Dallas 1 as the location. For the Operating System, select 7.x Minimal Install under Red Hat Enterprise Linux . For the machine profile, I will keep the default to 8x32 , but you could go down to 4x16 if you wish. If you already have a ssh key attached to your account, select it under SSH keys. If you don't have an SSH Key attached to your account, follow the next steps. 3.1.1.1 Create a SSH Key If you don't have an SSH key associated with your IBM Cloud account, follow the steps below to create an SSH key and add it to your IBM Cloud account. Start your terminal and navigate to a directory where you want to store your SSH Key and run the following command. ssh-keygen -m PEM -t rsa -f \"\\<email address>\" Hit enter for no passphrase when prompted. Next, type cat the .pub file that was just created. The naming convention will be the email address you entered in the previous command plus '.pub'. cat \\<email address>.pub Copy the entire output starting with ssh-rsa to your clipboard. Back in your browser, click New key . On the next screen, give a name for your key such as ssh-key-\\<initials>. Select the zero-to-cloud-native resource group and Dallas the Region. Paste in the key you just copied in the Public key field and then click on Add SSH key . 3.1.1.2 Create the Instance Template Back to creating a new Instance Template. We need to include the attach host files that we downloaded and edited in section 2. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-control-plane.sh. *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Next, we will create the same instance templates for the Satellite control plane for Dallas 2 and Dallas 3 locations. Dallas 2 Instance Template: The instance template for Dallas 2 should look exactly like the template for Dallas 1. To create the same template for Dallas 2, click on three dots next to the Dallas 1 template and select Duplicate. Make sure to enter the following settings: Name: satellite-02cn-control-plane-dal2 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 2 User Data -- import attachHost... control-plane Dallas 3 Instance Template: Follow the same steps and duplicate either the Dallas 1 or Dallas 2 control plane template and make sure to enter the following settings: Name: satellite-02cn-control-plane-dal3 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 3 User Data -- import attachHost... control-plane 3.1.2 VPC Instance Group for the control plane Now that we have our VPC Instance templates setup, we can now create an instance group based on the template. An instance group is a collection of like virtual server instances. You define how many instances to maintain in the group. You can set a static number of instances or choose to dynamically scale instances according to your requirements. Our instance group will allow us to scale the control plane using the same instance template we created in the previous step. To create a VPC instance group, click on Instance Groups under in the VPC Infrastructure menu under Auto Scale. On the next screen, click Create. We will be creating an instance group for each data center in our satellite location, Dallas 1, Dallas 2, and Dallas 3. Starting with Dallas 1, enter the following settings: Name: satellite-control-plane-dal1 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Note: it is very important to give a meaningful tag so we can tell all the different instances we have from one another. For example, if you have multiple clusters and multiple cloud services running in IBM Cloud tags can quickly identify instances from one another. Region: Dallas Next, select the instance template for this instance group. Since this is the instance group for Dallas 1, select with satellite-02cn-control-plane-dal1 instance template. Likewise, for subnet, select the satellite-02cn-dal1 subnet. Leave load balancer unchecked. We don't need a load balancer because ... KUNAL . Finally, select Static so the instance group will hold a set size. We need this because KUNAL ... The last thing we need to do is set the instance group size. For this tutorial, we will create 1 control plane master node in each data center. Select 1 for the intial size. For a production level system, you will want at least 2 hosts per zone. After entering all of these settings, click that you agree to provision this virtual server and click Create instance group. This will start provisioning a virtual machine based on the virtual instance template that we associated with this instance group, which is in Dallas 1. Next, we need to repeat the same steps for Dallas 2 and Dallas 3. Dallas 2 Instance Group Name: satellite-control-plane-dal2 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Region: Dallas Select the satellite-02cn-control-plane-dal2 instance template and the satellite-02cn-dal2 subnet. As with Dallas 1, keep the instance group size to 1 and create the instance group. We now have infrastructure provisioned for the control plane in Dallas 1 and Dallas 2, to finish provisioning all the infrastructure for the satellite control plane, repeat the same steps for Dallas 3. \\ Dallas 3 Instance Group Name: satellite-control-plane-dal3 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Region: Dallas Select the satellite-02cn-control-plane-dal3 instance template and the satellite-02cn-dal3 subnet. keep the instance group size to 1 and create the instance group. This completes provisioning the VPC infrastructure for our satellite control plane. 3.2 VPC Infrastructure for the Satellite IBM Cloud Managed OpenShift Worker Nodes Now that we have our control plane infrastructure provisioned, we can move on to provisioning our infrastructure for our IBM Cloud Managed OpenShift worker nodes. We will be following the same process to create infrastructure as we did for the control plane. As a reminder, we will be deploying a multizone cluster across Dallas 1, Dallas 2, and Dallas 3 with 2 worker nodes in each zone. 3.2.1 ROKS VPC Infrastructure Instance Template As we did with the control plane, we will be using instance templates to consistently build out like images for each of our worker nodes. 3.2.1.1 Dallas 1 Instance Template Starting with Dallas 1, from the VPC Infrastructure menu, select Instance Template . On the next screen, click Create . Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal1 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 1 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template. 3.2.1.2 Dallas 2 Instance Template Follow the same steps to create the same instance template for Dallas 2. To save time, you can copy the instance template for the Dallas 1 worker and modify the settings. Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal2 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 2 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template. 3.2.1.3 Dallas 3 Instance Template Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal3 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 3 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template. 3.2.2 ROKS VPC Infrastructure Instance Group Now that we have instance templates for each zone, we need to create an instance group, just like we did for the control plane, so that we can quickly provision and scale multiple worker nodes at the same time. 3.2.2.1 Dallas 1 Worker Node Instance Group To create a new instance group template, click on Instance templates from the VPC Infrastructure menu. From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas 1. Name: satellite-02cn-workers-dal1 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Under instance template, select the satellite-02cn-worker-dal1 template. Select the satellite-02cn-dal1 Subnet. And Select Dynamic of the instance group scaling method. For instance group size, select 2 as the minimum and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds . This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds . This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group. 3.2.2.2 Dallas 2 Worker Node Instance Group From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas2. Name: satellite-02cn-workers-dal2 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Select the satellite-02cn-worker-dal2 instance template For subnet, select the satellite-02cn-dal2 subnet and select Dynamic for instance group scaling. For instance group size, select 2 as the minim um and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds. This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds. This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group. 3.2.2.3 Dallas 3 Worker Node Instance Group From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas 3. Name: satellite-02cn-workers-dal3 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Select the satellite-02cn-worker-dal3 as the instance template. Select the satellite-02cn-dal3 subnet and keep Dynamic scaling checked. For instance group size, select 2 as the minim um and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds. This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds. This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group. 3.3 VPC Security Group Now that we have setup all our infrastructure, we need to setup our security group for the VPC to allow traffic into and out of our cluster. To modify the default security group, click on Security Groups under the VPC Infrastructure / Network menu. You will find a default security group has been created for you. Look for the security group associated with your Virtual Private cloud and click on it. On the screen, click on Manage rules . We will be creating a number of Inbound rules. For outbound we will keep allow all for any protocol. To create a new inbound rule, click on create in the Inbound rules section. Create an inbound rule to allow IBM Cloud to setup and manage your satellite location. Port min: 30000 Port max: 32767 Source Type: Any Protocol: TCP Repeat the same steps for the following ports. Access for Red Hat OpenShift Protocol: UDP Port min: 3000 Port max: 30767 Access the Red Hat OpenShift on IBM Cloud console Protocol: TCP Port min: 443 Port max: 443 VPN Connection Protocol: UDP Port min: 1194 Port max: 1194 Your security group should look like the following: Congratulations, you have now setup and configured VPC Infrastructure on IBM Cloud for your Satellite location!","title":"Vpc"},{"location":"vpc/vpc/#deploy-satellite-infrastructure-on-ibm-cloud-vpc","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com )","title":"Deploy Satellite Infrastructure on IBM Cloud VPC"},{"location":"vpc/vpc/#1-introduction","text":"As you learned in the previous section, IBM Cloud Satellite can be deployed anywhere that you want from onPrem, to a cloud provider such as AWS, Azure, GCP, to the edge, or even on IBM Cloud. The instructions here will show you how to provision infrastructure on IBM Cloud VPC. While certain other options and providers will have different instructions the same concepts will apply. To simulate a more realistic environment, we will be deploying a private only Virtual Private Cloud with no Internet Connectivity.","title":"1 - Introduction"},{"location":"vpc/vpc/#2-provision-ibm-cloud-virtual-private-cloud","text":"","title":"2 -- Provision IBM Cloud Virtual Private Cloud"},{"location":"vpc/vpc/#21-edit-attach-host-scripts","text":"In Section 14, when you first created your satellite location, you downloaded two 'attachHosts' scripts. These attachHost scripts are what tells IBM Cloud Satellite to use these hosts in your Satellite location. Before the attach host script can be ran, we need to run two commands on each instance to ensure the correct RedHat packages are installed. To automate running these scripts when the attach host script is ran, we need to edit both attach host scripts to include these commands. Open you code editor and open either attachHost file you downloaded. Look in the file for a line that starts with API_URL and add the following three lines of code: # enabling dependencies required by satellite subscription-manager refresh subscription-manager repos --enable=* Repeat the same steps for the other attachHost file.","title":"2.1 Edit Attach Host Scripts"},{"location":"vpc/vpc/#22-create-a-vpc-infrastructure-for-the-satellite-control-plane","text":"From your IBM Cloud menu, navigate to VPC Infrastructure and then select VPCs. To simulate a remote location, we will be creating a new private only VPC meaning there will be no connectivity outside of our VPC. From the Virtual Private Cloud page, click Create. Enter a name of the VPC, I will be using zero-to-cloud-native-satellite-vpc and select your zero-to-cloud-native resource group. Keep the remaining default settings and scroll down to New subnet for VPC. We will be created a multizone region across Dallas for our Satellite location. This means we will need to create a subnet for each zone. Starting with Dallas 1, give your subnet a meaningful name so you can find it later; I will be using satellite-02cn-dal1 and the zero-to-cloud-native resource group. Select Dallas1 as the location. Make sure to attach the Public Gateway attached. You can remove this later, but we need this enabled for setup and configuration. Keep the remaining settings as-is and click Create virtual private cloud . Next up, we need to create the two other subnets in Dallas 2 and Dallas 3 for our multizone location. To do so, from the IBM Cloud Menu under VPC Infrastructure, click on Subnets. On the next screen, click Create. Give you subnet for Dallas 2 a name, I will be using satellite-02cn-dal2, select the name of your virtual private cloud which should be zero-to-cloud-native-satellite-vpc, and the zero-to-cloud-native resource group. The location for this subnet should be Dallas 2. After entering all of these settings click on Create Subnet. Repeat the same steps to create a final subnet in Dallas 3. {width=\"6.5in\" height=\"2.25in\"}","title":"2.2 Create a VPC Infrastructure for the Satellite Control Plane"},{"location":"vpc/vpc/#3-create-vpc-infrastructure","text":"The first step in creating your satellite location is to provision infrastructure that your satellite location will use. In this tutorial we will be provisioning infrastructure in a VPC for both the control plane and the worker nodes for our IBM Cloud Managed OpenShift cluster.","title":"3 Create VPC Infrastructure"},{"location":"vpc/vpc/#31-vpc-infrastructure-for-the-satellite-control-plane","text":"We will start by provisioning the VPC infrastructure for the control plane. You can view this control plane as the master nodes for the IBM Cloud Managed OpenShift cluster will be creating.","title":"3.1 VPC Infrastructure for the Satellite Control Plane"},{"location":"vpc/vpc/#311-vpc-instancetemplate","text":"Now that we have a virtual private cloud configured with subnets, we can add hosts for the Satellite control plane to our VPC. The best way to create these VPC instances is to use an Instance Template. A VPC instance template is used to define instance details for provisioning our virtual servers for the control plan. This will enable us to quickly create consistent images for our control plane. To create an instance template, from the IBM Cloud menu, under VPC Infrastructure, expand Auto scale and then select Instance templates . On the next screen, click on Create to create your first instance template. We will be creating a template for each zone for our control plane. Starting with Dallas 1, give the template a meaningful name, I will use satellite-02cn-control-plane-dal1 . Select your zero-to-cloud-native-satellite-vpc VPC and the zero-cloud-native resource group. This template will be for Dallas 1 so also select Dallas 1 as the location. For the Operating System, select 7.x Minimal Install under Red Hat Enterprise Linux . For the machine profile, I will keep the default to 8x32 , but you could go down to 4x16 if you wish. If you already have a ssh key attached to your account, select it under SSH keys. If you don't have an SSH Key attached to your account, follow the next steps.","title":"3.1.1 VPC InstanceTemplate"},{"location":"vpc/vpc/#3111-create-a-ssh-key","text":"If you don't have an SSH key associated with your IBM Cloud account, follow the steps below to create an SSH key and add it to your IBM Cloud account. Start your terminal and navigate to a directory where you want to store your SSH Key and run the following command. ssh-keygen -m PEM -t rsa -f \"\\<email address>\" Hit enter for no passphrase when prompted. Next, type cat the .pub file that was just created. The naming convention will be the email address you entered in the previous command plus '.pub'. cat \\<email address>.pub Copy the entire output starting with ssh-rsa to your clipboard. Back in your browser, click New key . On the next screen, give a name for your key such as ssh-key-\\<initials>. Select the zero-to-cloud-native resource group and Dallas the Region. Paste in the key you just copied in the Public key field and then click on Add SSH key .","title":"3.1.1.1 Create a SSH Key"},{"location":"vpc/vpc/#3112-create-the-instance-template","text":"Back to creating a new Instance Template. We need to include the attach host files that we downloaded and edited in section 2. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-control-plane.sh. *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Next, we will create the same instance templates for the Satellite control plane for Dallas 2 and Dallas 3 locations. Dallas 2 Instance Template: The instance template for Dallas 2 should look exactly like the template for Dallas 1. To create the same template for Dallas 2, click on three dots next to the Dallas 1 template and select Duplicate. Make sure to enter the following settings: Name: satellite-02cn-control-plane-dal2 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 2 User Data -- import attachHost... control-plane Dallas 3 Instance Template: Follow the same steps and duplicate either the Dallas 1 or Dallas 2 control plane template and make sure to enter the following settings: Name: satellite-02cn-control-plane-dal3 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 3 User Data -- import attachHost... control-plane","title":"3.1.1.2 Create the Instance Template"},{"location":"vpc/vpc/#_1","text":"","title":""},{"location":"vpc/vpc/#312-vpc-instance-group-for-the-control-plane","text":"Now that we have our VPC Instance templates setup, we can now create an instance group based on the template. An instance group is a collection of like virtual server instances. You define how many instances to maintain in the group. You can set a static number of instances or choose to dynamically scale instances according to your requirements. Our instance group will allow us to scale the control plane using the same instance template we created in the previous step. To create a VPC instance group, click on Instance Groups under in the VPC Infrastructure menu under Auto Scale. On the next screen, click Create. We will be creating an instance group for each data center in our satellite location, Dallas 1, Dallas 2, and Dallas 3. Starting with Dallas 1, enter the following settings: Name: satellite-control-plane-dal1 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Note: it is very important to give a meaningful tag so we can tell all the different instances we have from one another. For example, if you have multiple clusters and multiple cloud services running in IBM Cloud tags can quickly identify instances from one another. Region: Dallas Next, select the instance template for this instance group. Since this is the instance group for Dallas 1, select with satellite-02cn-control-plane-dal1 instance template. Likewise, for subnet, select the satellite-02cn-dal1 subnet. Leave load balancer unchecked. We don't need a load balancer because ... KUNAL . Finally, select Static so the instance group will hold a set size. We need this because KUNAL ... The last thing we need to do is set the instance group size. For this tutorial, we will create 1 control plane master node in each data center. Select 1 for the intial size. For a production level system, you will want at least 2 hosts per zone. After entering all of these settings, click that you agree to provision this virtual server and click Create instance group. This will start provisioning a virtual machine based on the virtual instance template that we associated with this instance group, which is in Dallas 1. Next, we need to repeat the same steps for Dallas 2 and Dallas 3. Dallas 2 Instance Group Name: satellite-control-plane-dal2 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Region: Dallas Select the satellite-02cn-control-plane-dal2 instance template and the satellite-02cn-dal2 subnet. As with Dallas 1, keep the instance group size to 1 and create the instance group. We now have infrastructure provisioned for the control plane in Dallas 1 and Dallas 2, to finish provisioning all the infrastructure for the satellite control plane, repeat the same steps for Dallas 3. \\ Dallas 3 Instance Group Name: satellite-control-plane-dal3 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-control-plane Region: Dallas Select the satellite-02cn-control-plane-dal3 instance template and the satellite-02cn-dal3 subnet. keep the instance group size to 1 and create the instance group. This completes provisioning the VPC infrastructure for our satellite control plane.","title":"3.1.2 VPC Instance Group for the control plane"},{"location":"vpc/vpc/#32-vpc-infrastructure-for-the-satellite-ibm-cloud-managed-openshift-worker-nodes","text":"Now that we have our control plane infrastructure provisioned, we can move on to provisioning our infrastructure for our IBM Cloud Managed OpenShift worker nodes. We will be following the same process to create infrastructure as we did for the control plane. As a reminder, we will be deploying a multizone cluster across Dallas 1, Dallas 2, and Dallas 3 with 2 worker nodes in each zone.","title":"3.2 VPC Infrastructure for the Satellite IBM Cloud Managed OpenShift Worker Nodes"},{"location":"vpc/vpc/#321-roks-vpc-infrastructure-instance-template","text":"As we did with the control plane, we will be using instance templates to consistently build out like images for each of our worker nodes.","title":"3.2.1 ROKS VPC Infrastructure Instance Template"},{"location":"vpc/vpc/#_2","text":"","title":""},{"location":"vpc/vpc/#3211-dallas-1-instance-template","text":"Starting with Dallas 1, from the VPC Infrastructure menu, select Instance Template . On the next screen, click Create . Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal1 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 1 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template.","title":"3.2.1.1 Dallas 1 Instance Template"},{"location":"vpc/vpc/#3212-dallas-2-instance-template","text":"Follow the same steps to create the same instance template for Dallas 2. To save time, you can copy the instance template for the Dallas 1 worker and modify the settings. Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal2 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 2 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template.","title":"3.2.1.2 Dallas 2 Instance Template"},{"location":"vpc/vpc/#3213-dallas-3-instance-template","text":"Enter the following settings for the next Instance template. Name: satellite-02cn-worker-dal3 Virtual Private Cloud: zero-to-cloud-native-satellite-vpc Resource Group: zero-to-cloud-native Location: Dallas 3 In the Operating System Section, select Red Hat Enterprise Linux 7.x Minimal Install . For the flavor we are going to go with 16x64 worker nodes. To change the profile, click on View all profiles. On the profiles screen, select 16x64 and click Save. We need to include the attach host files that we downloaded and edited. To include this file on our instance images, click on Import user data . On the next screen, select sat-host-check and attachHost-satellite-02cn-worker.sh . *IMPORTANT -- make sure you followed the instructions in section 2.2 Edit Attach Host Scripts before importing this file. Finally, click Create instance template.","title":"3.2.1.3 Dallas 3 Instance Template"},{"location":"vpc/vpc/#322-roks-vpc-infrastructure-instance-group","text":"Now that we have instance templates for each zone, we need to create an instance group, just like we did for the control plane, so that we can quickly provision and scale multiple worker nodes at the same time.","title":"3.2.2 ROKS VPC Infrastructure Instance Group"},{"location":"vpc/vpc/#3221-dallas-1-worker-node-instance-group","text":"To create a new instance group template, click on Instance templates from the VPC Infrastructure menu. From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas 1. Name: satellite-02cn-workers-dal1 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Under instance template, select the satellite-02cn-worker-dal1 template. Select the satellite-02cn-dal1 Subnet. And Select Dynamic of the instance group scaling method. For instance group size, select 2 as the minimum and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds . This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds . This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group.","title":"3.2.2.1 Dallas 1 Worker Node Instance Group"},{"location":"vpc/vpc/#3222-dallas-2-worker-node-instance-group","text":"From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas2. Name: satellite-02cn-workers-dal2 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Select the satellite-02cn-worker-dal2 instance template For subnet, select the satellite-02cn-dal2 subnet and select Dynamic for instance group scaling. For instance group size, select 2 as the minim um and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds. This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds. This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group.","title":"3.2.2.2 Dallas 2 Worker Node Instance Group"},{"location":"vpc/vpc/#3223-dallas-3-worker-node-instance-group","text":"From the Instance Group screen, click on Create. Enter the following settings to create a new Instance Group for Dallas 3. Name: satellite-02cn-workers-dal3 Resource Group: zero-to-cloud-native Tags: env:satellite-02cn-workers Region: Dallas Select the satellite-02cn-worker-dal3 as the instance template. Select the satellite-02cn-dal3 subnet and keep Dynamic scaling checked. For instance group size, select 2 as the minim um and 6 as the maximum . This means our cluster will have a minimum of at least 2 worker nodes and will be able to scale to 6 based on the workload. Set the aggregation window to 300 seconds. This means the scaling metrics will be scanned very 300 seconds. Set the cooldown period to 3000 seconds. This is how many seconds scaling will pause after scaling so we don't scale unnecessarily. Finally, click that you agree to provision the number of instances we have indicated, and click on Create instance group.","title":"3.2.2.3 Dallas 3 Worker Node Instance Group"},{"location":"vpc/vpc/#33-vpc-security-group","text":"Now that we have setup all our infrastructure, we need to setup our security group for the VPC to allow traffic into and out of our cluster. To modify the default security group, click on Security Groups under the VPC Infrastructure / Network menu. You will find a default security group has been created for you. Look for the security group associated with your Virtual Private cloud and click on it. On the screen, click on Manage rules . We will be creating a number of Inbound rules. For outbound we will keep allow all for any protocol. To create a new inbound rule, click on create in the Inbound rules section. Create an inbound rule to allow IBM Cloud to setup and manage your satellite location. Port min: 30000 Port max: 32767 Source Type: Any Protocol: TCP Repeat the same steps for the following ports. Access for Red Hat OpenShift Protocol: UDP Port min: 3000 Port max: 30767 Access the Red Hat OpenShift on IBM Cloud console Protocol: TCP Port min: 443 Port max: 443 VPN Connection Protocol: UDP Port min: 1194 Port max: 1194 Your security group should look like the following: Congratulations, you have now setup and configured VPC Infrastructure on IBM Cloud for your Satellite location!","title":"3.3 VPC Security Group"},{"location":"vpn/vpn/","text":"Create a OpenVPN Server and Client To Connect to a Private Network Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com ) 1 - Introduction In this section, we will be setting up an OpenVPN connection to connect to our private only satellite cluster that is running on a private only VPC. By deploying your cluster on a private only cluster adds in an additional layer of security and in the case of this tutorial series offers a more realistic scenario in deploying to a remote satellite location. In order to setup this VPN connection, we will need to deploy both a server and a client. For the server, we will deploy a 'jump server' VSI in our zero to cloud native VPC and then use your workstation as the client. 2 - VPN Server As a reference, this guide will follow the basic instructions below, however there are a couple of different settings that you will need in place to work on your virtual private cloud. https://www.digitalocean.com/community/tutorials/how-to-set-up-and-configure-an-openvpn-server-on-centos-7 To get started, the first thing we will do is provision a VSI for our VPN Server. 2.1 Provision VPC Infrastructure Start by navigating to VPC Infrastructure and then select VPC Instances. On the next screen, click on Create to create a new VPC Instance. Enter the following settings on the next screen: Name: vpn-02cn Resource Group: zero-to-cloud-native Location: Dallas 1 Operating System: Ubuntu Linux 16.04 LTS In the profile section, select Balanced bx2-4x16 and make sure to select your SSH Key. In the networking section, select zero-to-cloud-native-satellite-vpc . Finally, on the right hand side of the screen, click on Create virtual server instance. Next, since this VSI will be our VPN Server, we need to give it a public IP. To do so, click on Floating IPs in VPC / Network menu. On the next screen, click on Create to create a new floating IP. On the next screen, enter the following settings for the new floating IP. Name: vpn-02cn-ip Resource Group: zero-to-cloud-native Location: Dallas 1 Instance to bind: vpn-02cn After entering these settings, click on Reserve IP . Hover above the floating IP you just created and click Copy IP address . Keep track of this floating IP as we will need to throughout this tutorial. Now that we have a floating IP, we can SSH into the virtual server instance we created to setup our VPN connection. 2.2 Configure OpenVPN Server Now that we have our VSI provisioned with a public IP, we can now start configuring it. Start your terminal and SSH into the VSI. ssh -i ~/.ssh/kevincollins@us.ibm.com <root@169.48.155.171> *note: make sure to select the location of your SSH key that we previously setup. 2.2.1 Install OpenVPN Next, we will install OpenVPN. Run the following commands from your terminal. For more background on each command, refer to the source here: https://www.digitalocean.com/community/tutorials/how-to-set-up-an-openvpn-server-on-ubuntu-16-04 sudo apt-get update sudo apt-get install openvpn easy-rsa make-cadir ~/openvpn-ca cd ~/openvpn-ca The OpenVPN connection will be secured by certificates that we need to create. To create certificates, there are a number of variables that we need to set. To do so, you will need to edit a file called vars. vi vars Scroll down in the file and enter values as follows: *Note, this is informational only and you can add whatever you want here. After making the changes, save the file. Going back to configuring the OpenVPN server, enter these commands: cd ~/openvpn-ca source vars ./clean-all ./build-ca (Hit Enter to select all the default values ) ./build-key-server server (Hit Enter to select all the default values and hit 'y' twice to generate the certificate ) ./build-dh openvpn --genkey --secret keys/ta.key source vars ./build-key client1 cd keys cp ca.crt server.crt server.key ta.key dh2048.pem /etc/openvpn gunzip -c /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz | sudo tee /etc/openvpn/server.conf vi /etc/openvpn/server.conf Copy and paste the following into this file, make sure to enter the routes for your VPC, see below on how to do that. ################################################# # Sample OpenVPN 2.0 config file for # # IBM VPC # ################################################# port 1194 proto udp dev tun ca ca.crt cert server.crt key server.key # This file should be kept secret dh dh2048.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"dhcp-option DNS 8.8.8.8\" push \"dhcp-option DNS 8.8.4.4\" # update with routes from your VPC push \"route 10.240.0.0 255.255.192.0\" push \"route 10.240.64.0 255.255.192.0\" push \"route 10.240.128.0 255.255.192.0\" keepalive 10 120 tls-auth ta.key 0 # This file is secret cipher AES-128-CBC # AES auth SHA256 comp-lzo user nobody group nogroup persist-key persist-tun status openvpn-status.log verb 3 In order for the OpenVPN client to be able to connect to your VPC, you will need to create routes. The first step is finding out what address prefixes you have in your VPC. To find this out, navigate to your VPC in IBM Cloud. You will notice that there will be three prefixes, one for each location ( dallas 1, dallas 2, dallas 3). These are the values you need to enter as a route in the server.conf file. In my case, I have these address prefixes: 10.240.0.0/18 10.240.64.0/18 10.240.128.0/18 You will need to convert the CIDR range to a netmask. If you followed the earlier instructions for creating a VPC then your subnets will end in /18 which has a subnet mask of 255.255.192.0. If you have a different CIDR range, then you will need to figure out what the netmask should be. The following website will help with that if needed. http://www.sput.nl/internet/cidr-routing.html In my VPC, this results in the following routes: * push \"route 10.240.0.0 255.255.192.0\" push \"route 10.240.64.0 255.255.192.0\" push \"route 10.240.128.0 255.255.192.0\" The next file we need to update is sysctl.conf. vi /etc/sysctl.conf Uncomment the following line: net.ipv4.ip_forward = 1 sudo sysctl -p ip route | grep default Make note of the output, you will need to the interface name which comes after dev. In the case above, that is ens3. Now we need to edit another file for firewall rules vi /etc/ufw/before.rules Add these lines near the top: # START OPENVPN RULES # NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Allow traffic from OpenVPN client to wlp11s0 (change to the interface # you discovered!) -A POSTROUTING -s 10.8.0.0/8 -o ens3 -j MASQUERADE COMMIT # END OPENVPN RULES Make sure to change ens3 to the value you got in the previous step. Next, edit another file: vi /etc/default/ufw change DEFAULT_FORWARD_POLICY=\\\"ACCEPT\\\" Enter these commands to configure the firewall with the changes we just made: sudo ufw allow 1194/udp sudo ufw allow OpenSSH sudo ufw disable sudo ufw enable sudo systemctl start openvpn@server sudo systemctl status openvpn@server mkdir -p ~/client-configs/files chmod 700 ~/client-configs/files cp /usr/share/doc/openvpn/examples/sample-config-files/client.conf ~/client-configs/base.conf vi ~/client-configs/base.conf change the remote my-server-1 line to the floating IP of your VPN instance Uncomment the lines: user nobody group nogroup comment out the following lines: #ca ca.crt #cert client.crt #key client.key In the cipher section, add these lines: cipher AES-128-CBC auth SHA256 key-direction 1 Next create a file that your OpenVPN client will use and paste the following in it: vi ~/client-configs/make_config.sh #!/bin/bash # First argument: Client identifier KEY_DIR=~/openvpn-ca/keys OUTPUT_DIR=~/client-configs/files BASE_CONFIG=~/client-configs/base.conf cat ${BASE_CONFIG} \\ <(echo -e '<ca>') \\ ${KEY_DIR}/ca.crt \\ <(echo -e '</ca>\\n<cert>') \\ ${KEY_DIR}/${1}.crt \\ <(echo -e '</cert>\\n<key>') \\ ${KEY_DIR}/${1}.key \\ <(echo -e '</key>\\n<tls-auth>') \\ ${KEY_DIR}/ta.key \\ <(echo -e '</tls-auth>') \\ > ${OUTPUT_DIR}/${1}.ovpn Change permissions of the file and run it: chmod 700 ~/client-configs/make_config.sh cd ~/client-configs ./make_config.sh client1 Finally, you made it, your OpenVPN server is complete! Exit out of the SSH session that is connected to your VPN VSI. 2.2 Configure OpenVPN Server Back on your terminal to your local machine, we need to create an OpenVPN client. Start by copying the certificates you just created on your VPN server to your local machine. mkdir vpn-02cn cd vpn-02cn Next, copy the client file you created on the VPC VPN Instance to your local machine. Make sure to update the following command to use the public IP of your VPC VPN instance. scp -i ~/.ssh/kevincollins@us.ibm.com root@169.48.152.73:/root/client-configs/files/client1.ovpn . Next -- Install the OpenVPN client on your mac following these instructions: https://openvpn.net/vpn-server-resources/installation-guide-for-openvpn-connect-client-on-macos/ After installing OpenVPN Client, start it. Click on File, then select the client.ovpn file you just created. After you connect, your VPN service should look like the following:","title":"Vpn"},{"location":"vpn/vpn/#create-a-openvpn-server-and-client-to-connect-to-a-private-network","text":"Kevin Collins ( kevincollins@us.ibm.com ) Kunal Malhotra ( kunal.malhotra3@ibm.com )","title":"Create a OpenVPN Server and Client To Connect to a Private Network"},{"location":"vpn/vpn/#1-introduction","text":"In this section, we will be setting up an OpenVPN connection to connect to our private only satellite cluster that is running on a private only VPC. By deploying your cluster on a private only cluster adds in an additional layer of security and in the case of this tutorial series offers a more realistic scenario in deploying to a remote satellite location. In order to setup this VPN connection, we will need to deploy both a server and a client. For the server, we will deploy a 'jump server' VSI in our zero to cloud native VPC and then use your workstation as the client.","title":"1 - Introduction"},{"location":"vpn/vpn/#2-vpn-server","text":"As a reference, this guide will follow the basic instructions below, however there are a couple of different settings that you will need in place to work on your virtual private cloud. https://www.digitalocean.com/community/tutorials/how-to-set-up-and-configure-an-openvpn-server-on-centos-7 To get started, the first thing we will do is provision a VSI for our VPN Server.","title":"2 - VPN Server"},{"location":"vpn/vpn/#21-provision-vpc-infrastructure","text":"Start by navigating to VPC Infrastructure and then select VPC Instances. On the next screen, click on Create to create a new VPC Instance. Enter the following settings on the next screen: Name: vpn-02cn Resource Group: zero-to-cloud-native Location: Dallas 1 Operating System: Ubuntu Linux 16.04 LTS In the profile section, select Balanced bx2-4x16 and make sure to select your SSH Key. In the networking section, select zero-to-cloud-native-satellite-vpc . Finally, on the right hand side of the screen, click on Create virtual server instance. Next, since this VSI will be our VPN Server, we need to give it a public IP. To do so, click on Floating IPs in VPC / Network menu. On the next screen, click on Create to create a new floating IP. On the next screen, enter the following settings for the new floating IP. Name: vpn-02cn-ip Resource Group: zero-to-cloud-native Location: Dallas 1 Instance to bind: vpn-02cn After entering these settings, click on Reserve IP . Hover above the floating IP you just created and click Copy IP address . Keep track of this floating IP as we will need to throughout this tutorial. Now that we have a floating IP, we can SSH into the virtual server instance we created to setup our VPN connection.","title":"2.1 Provision VPC Infrastructure"},{"location":"vpn/vpn/#22-configure-openvpn-server","text":"Now that we have our VSI provisioned with a public IP, we can now start configuring it. Start your terminal and SSH into the VSI. ssh -i ~/.ssh/kevincollins@us.ibm.com <root@169.48.155.171> *note: make sure to select the location of your SSH key that we previously setup.","title":"2.2 Configure OpenVPN Server"},{"location":"vpn/vpn/#221-install-openvpn","text":"Next, we will install OpenVPN. Run the following commands from your terminal. For more background on each command, refer to the source here: https://www.digitalocean.com/community/tutorials/how-to-set-up-an-openvpn-server-on-ubuntu-16-04 sudo apt-get update sudo apt-get install openvpn easy-rsa make-cadir ~/openvpn-ca cd ~/openvpn-ca The OpenVPN connection will be secured by certificates that we need to create. To create certificates, there are a number of variables that we need to set. To do so, you will need to edit a file called vars. vi vars Scroll down in the file and enter values as follows: *Note, this is informational only and you can add whatever you want here. After making the changes, save the file. Going back to configuring the OpenVPN server, enter these commands: cd ~/openvpn-ca source vars ./clean-all ./build-ca (Hit Enter to select all the default values ) ./build-key-server server (Hit Enter to select all the default values and hit 'y' twice to generate the certificate ) ./build-dh openvpn --genkey --secret keys/ta.key source vars ./build-key client1 cd keys cp ca.crt server.crt server.key ta.key dh2048.pem /etc/openvpn gunzip -c /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz | sudo tee /etc/openvpn/server.conf vi /etc/openvpn/server.conf Copy and paste the following into this file, make sure to enter the routes for your VPC, see below on how to do that. ################################################# # Sample OpenVPN 2.0 config file for # # IBM VPC # ################################################# port 1194 proto udp dev tun ca ca.crt cert server.crt key server.key # This file should be kept secret dh dh2048.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \"dhcp-option DNS 8.8.8.8\" push \"dhcp-option DNS 8.8.4.4\" # update with routes from your VPC push \"route 10.240.0.0 255.255.192.0\" push \"route 10.240.64.0 255.255.192.0\" push \"route 10.240.128.0 255.255.192.0\" keepalive 10 120 tls-auth ta.key 0 # This file is secret cipher AES-128-CBC # AES auth SHA256 comp-lzo user nobody group nogroup persist-key persist-tun status openvpn-status.log verb 3 In order for the OpenVPN client to be able to connect to your VPC, you will need to create routes. The first step is finding out what address prefixes you have in your VPC. To find this out, navigate to your VPC in IBM Cloud. You will notice that there will be three prefixes, one for each location ( dallas 1, dallas 2, dallas 3). These are the values you need to enter as a route in the server.conf file. In my case, I have these address prefixes: 10.240.0.0/18 10.240.64.0/18 10.240.128.0/18 You will need to convert the CIDR range to a netmask. If you followed the earlier instructions for creating a VPC then your subnets will end in /18 which has a subnet mask of 255.255.192.0. If you have a different CIDR range, then you will need to figure out what the netmask should be. The following website will help with that if needed. http://www.sput.nl/internet/cidr-routing.html In my VPC, this results in the following routes: * push \"route 10.240.0.0 255.255.192.0\" push \"route 10.240.64.0 255.255.192.0\" push \"route 10.240.128.0 255.255.192.0\" The next file we need to update is sysctl.conf. vi /etc/sysctl.conf Uncomment the following line: net.ipv4.ip_forward = 1 sudo sysctl -p ip route | grep default Make note of the output, you will need to the interface name which comes after dev. In the case above, that is ens3. Now we need to edit another file for firewall rules vi /etc/ufw/before.rules Add these lines near the top: # START OPENVPN RULES # NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Allow traffic from OpenVPN client to wlp11s0 (change to the interface # you discovered!) -A POSTROUTING -s 10.8.0.0/8 -o ens3 -j MASQUERADE COMMIT # END OPENVPN RULES Make sure to change ens3 to the value you got in the previous step. Next, edit another file: vi /etc/default/ufw change DEFAULT_FORWARD_POLICY=\\\"ACCEPT\\\" Enter these commands to configure the firewall with the changes we just made: sudo ufw allow 1194/udp sudo ufw allow OpenSSH sudo ufw disable sudo ufw enable sudo systemctl start openvpn@server sudo systemctl status openvpn@server mkdir -p ~/client-configs/files chmod 700 ~/client-configs/files cp /usr/share/doc/openvpn/examples/sample-config-files/client.conf ~/client-configs/base.conf vi ~/client-configs/base.conf change the remote my-server-1 line to the floating IP of your VPN instance Uncomment the lines: user nobody group nogroup comment out the following lines: #ca ca.crt #cert client.crt #key client.key In the cipher section, add these lines: cipher AES-128-CBC auth SHA256 key-direction 1 Next create a file that your OpenVPN client will use and paste the following in it: vi ~/client-configs/make_config.sh #!/bin/bash # First argument: Client identifier KEY_DIR=~/openvpn-ca/keys OUTPUT_DIR=~/client-configs/files BASE_CONFIG=~/client-configs/base.conf cat ${BASE_CONFIG} \\ <(echo -e '<ca>') \\ ${KEY_DIR}/ca.crt \\ <(echo -e '</ca>\\n<cert>') \\ ${KEY_DIR}/${1}.crt \\ <(echo -e '</cert>\\n<key>') \\ ${KEY_DIR}/${1}.key \\ <(echo -e '</key>\\n<tls-auth>') \\ ${KEY_DIR}/ta.key \\ <(echo -e '</tls-auth>') \\ > ${OUTPUT_DIR}/${1}.ovpn Change permissions of the file and run it: chmod 700 ~/client-configs/make_config.sh cd ~/client-configs ./make_config.sh client1 Finally, you made it, your OpenVPN server is complete! Exit out of the SSH session that is connected to your VPN VSI.","title":"2.2.1 Install OpenVPN"},{"location":"vpn/vpn/#22-configure-openvpn-server_1","text":"Back on your terminal to your local machine, we need to create an OpenVPN client. Start by copying the certificates you just created on your VPN server to your local machine. mkdir vpn-02cn cd vpn-02cn Next, copy the client file you created on the VPC VPN Instance to your local machine. Make sure to update the following command to use the public IP of your VPC VPN instance. scp -i ~/.ssh/kevincollins@us.ibm.com root@169.48.152.73:/root/client-configs/files/client1.ovpn . Next -- Install the OpenVPN client on your mac following these instructions: https://openvpn.net/vpn-server-resources/installation-guide-for-openvpn-connect-client-on-macos/ After installing OpenVPN Client, start it. Click on File, then select the client.ovpn file you just created. After you connect, your VPN service should look like the following:","title":"2.2 Configure OpenVPN Server"}]}